from dotenv import load_dotenv
import os
from langchain_neo4j import Neo4jGraph
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores.neo4j_vector import Neo4jVector
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from typing import List, Dict


# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

NEO4J_URI = os.getenv("NEO4J_URI")
NEO4J_USER = os.getenv("NEO4J_USER")
NEO4J_PASS = os.getenv("NEO4J_PASS")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
INDEX_NAME = os.getenv("INDEX_NAME")

# Neo4j Graph ì—°ê²°
graph = Neo4jGraph(url=NEO4J_URI, username=NEO4J_USER, password=NEO4J_PASS)

# Vector DB ì„¤ì • (graph_embedding.pyì™€ ë™ì¼í•œ ì„¤ì •)
MODEL_NAME = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
embedding_model = SentenceTransformerEmbeddings(model_name=MODEL_NAME)

# Neo4j Vector DB ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
neo4j_vector_db = Neo4jVector.from_existing_graph(
    embedding=embedding_model,
    url=NEO4J_URI,
    username=NEO4J_USER,
    password=NEO4J_PASS,
    index_name=INDEX_NAME,          
    node_label="HSItem",            
    text_node_properties=["description"],
    embedding_node_property="embedding",
)

def get_vector_candidates(user_query: str, k: int = 5) -> List[str]:
    """Vector Searchë¥¼ ì‹¤í–‰í•˜ì—¬ ìƒìœ„ kê°œì˜ í›„ë³´ ì½”ë“œ(4~6ìë¦¬)ë¥¼ ë°˜í™˜"""
    # neo4j_vector_db ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰
    search_results = neo4j_vector_db.similarity_search(user_query, k=k)
    
    # 4ìë¦¬ ë˜ëŠ” 6ìë¦¬ ì½”ë“œë§Œ ì¶”ì¶œí•˜ì—¬ ìƒìœ„ ë ˆë²¨ë¡œ ì‚¬ìš© (ì „ëµì  í•„í„°ë§)
    candidate_codes = set()
    for doc in search_results:
        code = doc.metadata.get('code')
        if code and len(code) in [4, 6]:
             candidate_codes.add(code)
    
    return list(candidate_codes)

# # ì˜ˆì‹œ: 'LED ë¨í”„'ì— ëŒ€í•œ í›„ë³´ ì½”ë“œ ê²€ìƒ‰
# user_input = "Mules and hinnies; live"
# candidate_codes = get_vector_candidates(user_input)
# print(f"Vector Search í›„ë³´ ì½”ë“œ: {candidate_codes}") 



def get_graph_context(candidate_codes: List[str]) -> str:
    """í›„ë³´ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì¸µ ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê³  LLM Contextë¥¼ ìƒì„±"""
    
    # ğŸš¨ ë™ì  Cypher ì¿¼ë¦¬ ìƒì„±
    # candidates_str = "['8541', '9405']" í˜•íƒœì˜ Cypher ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    candidates_str = str(candidate_codes).replace("'", '"')

    # LLMì´ ì§ì ‘ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ëŒ€ì‹ , ì½”ë“œë¥¼ ì‚½ì…í•˜ì—¬ ì‹¤í–‰
    cypher_query = f"""
    UNWIND {candidates_str} AS root_code_str
    MATCH p = (root:HSItem {{code: root_code_str}})-[:HAS_CHILD*1..]->(n)
    WHERE NOT (n)-[:HAS_CHILD]->()
    RETURN nodes(p) AS Path_Nodes, relationships(p) AS Path_Relationships
    """
    
    results = graph.query(cypher_query)
    
    final_context = "# [ê²€ìƒ‰ëœ HS Code ê³„ì¸µ êµ¬ì¡° ë°ì´í„°]\n\n"
    
    # --- LLM Context ë¬¸ìì—´ ë³€í™˜ ë¡œì§ ---
    for result in results:
        nodes = result['Path_Nodes']
        
        # 1. ì‹œê°ì  ê³„ì¸µ ê²½ë¡œ êµ¬ì„± (ê³ ê°ë‹˜ì˜ ì˜ˆì‹œ í˜•íƒœ)
        if not nodes: continue

        path_text = ""
        table_rows = []
        
        for i, node in enumerate(nodes):
            code = node['code']
            desc = node['description']
            
            # ê²½ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
            if i == 0:
                path_text += f"[ì‹œì‘ ë…¸ë“œ: {code} ({desc})]\n"
                level_desc = "ìƒìœ„ ë ˆë²¨"
            elif i == len(nodes) - 1:
                path_text += f"    |--[:HAS_CHILD]-> [ìµœì¢… ë…¸ë“œ: {code} ({desc})]\n"
                level_desc = "ìµœì¢… ë ˆë²¨"
            else:
                path_text += f"    |--[:HAS_CHILD]-> [ì¤‘ê°„ ë…¸ë“œ: {code} ({desc})]\n"
                level_desc = "ì¤‘ê°„ ë ˆë²¨"
            
            # í…Œì´ë¸” í–‰ ë°ì´í„° ìˆ˜ì§‘
            table_rows.append(f"| {code} | {desc} | {level_desc} |")
        
        # Contextì— ê²½ë¡œ ì¶”ê°€
        final_context += path_text + "\n"
        
        # 2. ì¶”ë¡  ìš”ì•½ í…Œì´ë¸” êµ¬ì„±
        final_context += "---"
        final_context += "\n[ì¶”ë¡  ìš”ì•½ í…Œì´ë¸”]\n"
        final_context += "| ì½”ë“œ | ì˜ë¬¸ í’ˆëª©ëª… | ê³„ì¸µ |\n"
        final_context += "|:---|:---|:---|\n"
        final_context += "\n".join(table_rows) + "\n\n"
    
    return final_context

# 3ë‹¨ê³„: LLM ë‹µë³€ ìƒì„± (ìµœì¢… RAG)
# LangChainì˜ PromptTemplateì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… Contextì™€ ì‚¬ìš©ì ì§ˆë¬¸ì„ LLMì— ì „ë‹¬í•©ë‹ˆë‹¤.




def generate_recommendation(user_input: str):
    # 1. Context ê²€ìƒ‰
    context = get_graph_context(get_vector_candidates(user_input))
    # 2. LLM Prompt êµ¬ì„±
    template = """
    ë‹¹ì‹ ì€ HS Code ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ [ê²€ìƒ‰ëœ HS Code ê³„ì¸µ êµ¬ì¡° ë°ì´í„°] ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ìƒí’ˆì— ê°€ì¥ ì í•©í•œ 10ìë¦¬ HS Codeë¥¼ ì¶”ì²œí•˜ê³ , 
    ì™œ ê·¸ ì½”ë“œë¥¼ ì„ íƒí–ˆëŠ”ì§€ ê³„ì¸µ ê²½ë¡œë¥¼ ì„¤ëª…í•˜ì‹­ì‹œì˜¤. 
    ë§Œì•½ ì—¬ëŸ¬ ê²½ë¡œê°€ ê²€ìƒ‰ë˜ì—ˆë‹¤ë©´, ëª¨ë“  ê²½ë¡œë¥¼ ì œì‹œí•˜ê³  ìµœì¢… ì„ íƒì„ ì‚¬ìš©ìì—ê²Œ ë§¡ê¸°ì‹­ì‹œì˜¤.

    ì‚¬ìš©ì ìƒí’ˆ: {user_input}

    [ê²€ìƒ‰ëœ HS Code ê³„ì¸µ êµ¬ì¡° ë°ì´í„°]:
    {context}
    """
    
    prompt = ChatPromptTemplate.from_template(template)
    
    # 3. LLM Chain ì‹¤í–‰
    chain = prompt | ChatOpenAI(model="gpt-4-turbo") 
    
    response = chain.invoke({"user_input": user_input, "context": context})
    
    return response.content

# ğŸš€ ìµœì¢… ì‹¤í–‰ 
print(generate_recommendation("ë°©ë¶€ì²˜ë¦¬í•œ ì ì†¡ ë‚˜ë¬´"))
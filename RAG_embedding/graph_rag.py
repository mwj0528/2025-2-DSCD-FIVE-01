from dotenv import load_dotenv
import os
import random
import numpy as np
from langchain_neo4j import Neo4jGraph
from langchain_community.embeddings import SentenceTransformerEmbeddings
from langchain_community.vectorstores.neo4j_vector import Neo4jVector
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from sentence_transformers import CrossEncoder
import torch
from rank_bm25 import BM25Okapi
import re
from typing import List, Dict, Optional


# ===== ìž¬í˜„ì„±ì„ ìœ„í•œ ëžœë¤ ì‹œë“œ ì„¤ì • =====
def set_all_seeds(seed: int = 42):
    """
    ëª¨ë“  ëžœë¤ ì‹œë“œë¥¼ ê³ ì •í•˜ì—¬ ìž¬í˜„ì„± í™•ë³´
    
    Args:
        seed: ëžœë¤ ì‹œë“œ ê°’ (ê¸°ë³¸ê°’: 42)
    """
    # Python ë‚´ìž¥ random
    random.seed(seed)
    
    # NumPy
    np.random.seed(seed)
    
    # PyTorch
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # PyTorch ìž¬í˜„ì„± ì„¤ì •
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # Python hash seed (ë”•ì…”ë„ˆë¦¬ ìˆœì„œ ë“±ì— ì˜í–¥)
    os.environ['PYTHONHASHSEED'] = str(seed)


def _is_openai_embedding_model(model_name: Optional[str]) -> bool:
    return bool(model_name) and model_name.startswith("text-embedding-")


class GraphRAG:
    """HS Code ì¶”ì²œì„ ìœ„í•œ Graph RAG í´ëž˜ìŠ¤"""
    
    def __init__(
        self,
        use_graph_rerank: bool = False,
        graph_rerank_model: str = None,
        graph_rerank_top_m: int = 5,
        use_graph_hybrid_rrf: bool = False,
        graph_bm25_k: int = 5,
        graph_rrf_k: int = 60,
        graph_embed_model: Optional[str] = None,
        graph_openai_api_key: Optional[str] = None,
    ):
        """GraphRAG ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”"""
        # .env íŒŒì¼ ë¡œë“œ
        load_dotenv()
        
        # ìž¬í˜„ì„±ì„ ìœ„í•œ ëžœë¤ ì‹œë“œ ì„¤ì •
        seed = int(os.getenv("SEED", "42"))
        set_all_seeds(seed)
        
        # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
        self.NEO4J_URI = os.getenv("NEO4J_URI")
        self.NEO4J_USER = os.getenv("NEO4J_USER")
        self.NEO4J_PASS = os.getenv("NEO4J_PASS")
        self.OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
        self.INDEX_NAME = os.getenv("INDEX_NAME")
        self.DEFAULT_GRAPH_RERANK_MODEL = os.getenv("GRAPH_RERANK_MODEL", "BAAI/bge-reranker-v2-m3")
        self.use_graph_rerank = bool(use_graph_rerank)
        self.graph_rerank_model = graph_rerank_model or self.DEFAULT_GRAPH_RERANK_MODEL
        try:
            self.graph_rerank_top_m = max(1, int(graph_rerank_top_m))
        except Exception:
            self.graph_rerank_top_m = 5
        # Hybrid (RRF) ì„¤ì •
        self.use_graph_hybrid_rrf = bool(use_graph_hybrid_rrf)
        try:
            self.graph_bm25_k = max(1, int(graph_bm25_k))
        except Exception:
            self.graph_bm25_k = 5
        try:
            self.graph_rrf_k = max(1, int(graph_rrf_k))
        except Exception:
            self.graph_rrf_k = 60
        
        # Neo4j Graph ì—°ê²°
        self.graph = Neo4jGraph(
            url=self.NEO4J_URI, 
            username=self.NEO4J_USER, 
            password=self.NEO4J_PASS
        )
        
        # Vector DB ì„¤ì •
        default_model = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        self.MODEL_NAME = graph_embed_model or default_model
        if _is_openai_embedding_model(self.MODEL_NAME):
            api_key = graph_openai_api_key or self.OPENAI_API_KEY
            if not api_key:
                raise ValueError(
                    f"OpenAI ìž„ë² ë”© ëª¨ë¸ '{self.MODEL_NAME}' ì‚¬ìš©ì„ ìœ„í•´ OPENAI_API_KEY ë˜ëŠ” ì „ìš© í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”."
                )
            self.embedding_model = OpenAIEmbeddings(model=self.MODEL_NAME, api_key=api_key)
        else:
            self.embedding_model = SentenceTransformerEmbeddings(
                model_name=self.MODEL_NAME,
                encode_kwargs={"normalize_embeddings": True}
            )
        
        # Neo4j Vector DB ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        self.neo4j_vector_db = Neo4jVector.from_existing_graph(
            embedding=self.embedding_model,
            url=self.NEO4J_URI,
            username=self.NEO4J_USER,
            password=self.NEO4J_PASS,
            index_name=self.INDEX_NAME,          
            node_label="HSItem",            
            text_node_properties=["description"],
            embedding_node_property="embedding",
        )

        # ì„ íƒì  ReRank ì´ˆê¸°í™”
        self._reranker = None
        if self.use_graph_rerank:
            try:
                device = "cuda" if torch.cuda.is_available() else "cpu"
                self._reranker = CrossEncoder(self.graph_rerank_model, device=device)
            except Exception as e:
                print(f"ê²½ê³ : Graph ReRank ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self._reranker = None

    def get_vector_candidates(self, user_query: str, k: int = 5) -> List[str]:
        """ìœ ì‚¬ë„ ìˆœì„œë¥¼ ìœ ì§€í•˜ë©´ì„œ 4/6ìžë¦¬ ì½”ë“œë§Œ í•„í„°ë§ í›„ ìµœëŒ€ kê°œ ë°˜í™˜.
        ë¶€ì¡±í•˜ë©´ ì ì¦ì ìœ¼ë¡œ ê²€ìƒ‰ ë²”ìœ„ë¥¼ ëŠ˜ë ¤ kê°œë¥¼ ìµœëŒ€í•œ ì±„ìš´ë‹¤.
        """
        current_fetch = max(20, k * 5)
        max_fetch = max(100, k * 50)
        last_count = -1

        while True:
            results = self.neo4j_vector_db.similarity_search(user_query, k=current_fetch)

            # ê¸°ë³¸: ìœ ì‚¬ë„ ìˆœì„œ ìœ ì§€í•˜ë©° í•„í„°ë§ + ì¤‘ë³µ ì œê±°
            base_ordered: List[str] = []
            seen: set = set()
            filtered_docs = []  # (code, text)
            for doc in results:
                code = doc.metadata.get("code")
                if not code:
                    continue
                # ì ê³¼ í•˜ì´í”ˆ ì œê±° í›„ ê¸¸ì´ í™•ì¸ (4ìžë¦¬ ë˜ëŠ” 6ìžë¦¬ë§Œ)
                code_clean = str(code).replace('.', '').replace('-', '')
                if len(code_clean) not in (4, 6):
                    continue
                text = getattr(doc, "page_content", "")
                if code not in seen:
                    seen.add(code)
                    base_ordered.append(code)
                filtered_docs.append((code, text))

            # ReRank í™œì„±í™” ì‹œ CrossEncoderë¡œ ìž¬ì •ë ¬
            if self.use_graph_rerank and self._reranker is not None and filtered_docs:
                try:
                    # ê°™ì€ ì½”ë“œê°€ ì—¬ëŸ¬ ë¬¸ì„œì— ë‚˜íƒ€ë‚˜ë©´ ìµœê³  ì ìˆ˜ ì±„íƒ
                    code_to_best_score = {}
                    pairs = [(user_query, text) for _, text in filtered_docs]
                    # ë©”ëª¨ë¦¬ ì ˆì•½: ìž‘ì€ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
                    batch_size = int(os.getenv("GRAPH_RERANK_BATCH_SIZE", "4"))
                    scores = self._reranker.predict(pairs, batch_size=batch_size, show_progress_bar=False)
                    for (code, _), s in zip(filtered_docs, scores):
                        score = float(s) if s is not None else 0.0
                        if code not in code_to_best_score or score > code_to_best_score[code]:
                            code_to_best_score[code] = score
                    reranked = sorted(code_to_best_score.items(), key=lambda x: x[1], reverse=True)
                    # ìƒìœ„ graph_rerank_top_më¥¼ ìš°ì„  ì‚¬ìš©í•˜ë˜ ìµœì¢… ë°˜í™˜ì€ ìµœëŒ€ kê°œê¹Œì§€
                    reranked_codes = [c for c, _ in reranked][:max(self.graph_rerank_top_m, k)]
                    # ë¶€ì¡± ì‹œ ê¸°ë³¸ ìˆœì„œë¡œ ë³´ì¶©
                    for c in base_ordered:
                        if len(reranked_codes) >= k:
                            break
                        if c not in reranked_codes:
                            reranked_codes.append(c)
                    if len(reranked_codes) >= k:
                        return reranked_codes[:k]
                except Exception as e:
                    print(f"ê²½ê³ : Graph ReRank ì¤‘ ì˜¤ë¥˜: {e}")

            # Hybrid RRF (Semantic + BM25) ì ìš©: filtered_docs í…ìŠ¤íŠ¸ì— ëŒ€í•´ BM25 êµ¬ì¶• í›„ RRF ê²°í•©
            if self.use_graph_hybrid_rrf and filtered_docs:
                try:
                    texts = [text or "" for _, text in filtered_docs]
                    tokens = [self._bm25_tokenize(t) for t in texts]
                    bm25 = BM25Okapi(tokens)
                    q_tokens = self._bm25_tokenize(user_query or "")
                    scores = bm25.get_scores(q_tokens)
                    # ì½”ë“œë³„ ìµœê³  ì ìˆ˜
                    code_to_best_bm25 = {}
                    for (code, _), s in zip(filtered_docs, scores):
                        score = float(s) if s is not None else 0.0
                        if code not in code_to_best_bm25 or score > code_to_best_bm25[code]:
                            code_to_best_bm25[code] = score
                    # semantic ìˆœìœ„
                    sem_rank = {c: r+1 for r, c in enumerate(base_ordered)}
                    # bm25 ìˆœìœ„
                    bm25_sorted = sorted(code_to_best_bm25.items(), key=lambda x: x[1], reverse=True)
                    bm25_rank = {c: r+1 for r, (c, _) in enumerate(bm25_sorted[:max(self.graph_bm25_k, k)])}
                    # RRF ìœµí•©
                    all_codes = set(sem_rank.keys()) | set(bm25_rank.keys())
                    fused = []
                    for code in all_codes:
                        r1 = sem_rank.get(code)
                        r2 = bm25_rank.get(code)
                        score = 0.0
                        if r1 is not None:
                            score += 1.0 / (self.graph_rrf_k + r1)
                        if r2 is not None:
                            score += 1.0 / (self.graph_rrf_k + r2)
                        fused.append((code, score))
                    fused.sort(key=lambda x: x[1], reverse=True)
                    rrf_codes = [c for c, _ in fused][:k]
                    if rrf_codes:
                        return rrf_codes
                except Exception as e:
                    print(f"ê²½ê³ : Graph RRF í•˜ì´ë¸Œë¦¬ë“œ ì‹¤íŒ¨: {e}")

            # ReRank/Hybrid ë¯¸ì‚¬ìš© ë˜ëŠ” ë¶ˆì¶©ë¶„ ì‹œ ê¸°ë³¸ ìˆœì„œ ë°˜í™˜ ì‹œë„
            if len(base_ordered) >= k:
                return base_ordered[:k]

            # ë” ê°€ì ¸ì™€ë„ ì¦ê°€ê°€ ì—†ê±°ë‚˜ ìƒí•œ ë„ë‹¬ ì‹œ ì¢…ë£Œ
            if len(results) == last_count or current_fetch >= max_fetch:
                # ë§ˆì§€ë§‰ìœ¼ë¡œ ê°€ëŠ¥í•œ ë§Œí¼ ë°˜í™˜
                if self.use_graph_rerank and self._reranker is not None:
                    # ìœ„ì—ì„œ ì´ë¯¸ ì‹œë„í–ˆìœ¼ë¯€ë¡œ base_ordered ë°˜í™˜
                    return base_ordered
                return base_ordered

            last_count = len(results)
            current_fetch = min(current_fetch * 2, max_fetch)

    def get_vector_candidates_with_text(self, user_query: str, k: int = 5) -> List[dict]:
        """ìœ ì‚¬ë„ ìˆœì„œë¥¼ ìœ ì§€í•˜ë©´ì„œ 4/6ìžë¦¬ ì½”ë“œë§Œ í•„í„°ë§ í›„ ìµœëŒ€ kê°œì— ëŒ€í•´ ëŒ€í‘œ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë°˜í™˜.
        ë°˜í™˜ í˜•ì‹: [{"code": str, "text": str}]
        """
        current_fetch = max(20, k * 5)
        max_fetch = max(100, k * 50)
        last_count = -1

        while True:
            results = self.neo4j_vector_db.similarity_search(user_query, k=current_fetch)

            # ê¸°ë³¸: ìœ ì‚¬ë„ ìˆœì„œ ìœ ì§€í•˜ë©° í•„í„°ë§ + ì½”ë“œë³„ ëŒ€í‘œ í…ìŠ¤íŠ¸ ì €ìž¥
            base_ordered: List[str] = []
            seen: set = set()
            filtered_docs = []  # (code, text)
            code_to_text = {}
            for doc in results:
                code = doc.metadata.get("code")
                if not code:
                    continue
                if len(code) not in (4, 6):
                    continue
                text = getattr(doc, "page_content", "")
                if code not in seen:
                    seen.add(code)
                    base_ordered.append(code)
                    code_to_text[code] = text
                filtered_docs.append((code, text))

            # ReRank í™œì„±í™” ì‹œ CrossEncoderë¡œ ìž¬ì •ë ¬í•˜ê³  ì½”ë“œë³„ ë² ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ ì„ íƒ
            if self.use_graph_rerank and self._reranker is not None and filtered_docs:
                try:
                    code_to_best_score = {}
                    code_to_best_text = {}
                    pairs = [(user_query, text) for _, text in filtered_docs]
                    batch_size = int(os.getenv("GRAPH_RERANK_BATCH_SIZE", "4"))
                    scores = self._reranker.predict(pairs, batch_size=batch_size, show_progress_bar=False)
                    for (code, text), s in zip(filtered_docs, scores):
                        score = float(s) if s is not None else 0.0
                        if code not in code_to_best_score or score > code_to_best_score[code]:
                            code_to_best_score[code] = score
                            code_to_best_text[code] = text
                    reranked = sorted(code_to_best_score.items(), key=lambda x: x[1], reverse=True)
                    reranked_codes = [c for c, _ in reranked][:max(self.graph_rerank_top_m, k)]
                    # ë¶€ì¡± ì‹œ ê¸°ë³¸ ìˆœì„œë¡œ ë³´ì¶©
                    for c in base_ordered:
                        if len(reranked_codes) >= k:
                            break
                        if c not in reranked_codes:
                            reranked_codes.append(c)
                    out = []
                    for c in reranked_codes[:k]:
                        out.append({"code": c, "text": code_to_best_text.get(c, code_to_text.get(c, ""))})
                    if out:
                        return out
                except Exception as e:
                    print(f"ê²½ê³ : Graph ReRank ì¤‘ ì˜¤ë¥˜: {e}")

            # Hybrid RRF ë¯¸ì‚¬ìš© ë˜ëŠ” ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ìˆœì„œì—ì„œ ë°˜í™˜
            if len(base_ordered) >= k:
                return [{"code": c, "text": code_to_text.get(c, "")} for c in base_ordered[:k]]

            if len(results) == last_count or current_fetch >= max_fetch:
                # ê°€ëŠ¥í•œ ë§Œí¼ ë°˜í™˜
                return [{"code": c, "text": code_to_text.get(c, "")} for c in base_ordered]

            last_count = len(results)
            current_fetch = min(current_fetch * 2, max_fetch)

    def _bm25_tokenize(self, text: str):
        if not text:
            return []
        s = str(text).lower()
        s = re.sub(r"[%ãŽœ]+", " ", s)
        return [t for t in re.findall(r"[a-z0-9ê°€-íž£]+", s) if len(t) >= 2]

    def get_graph_context(self, candidate_codes: List[str]) -> str:
        """í›„ë³´ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì¸µ ê²½ë¡œë¥¼ íƒìƒ‰í•˜ê³  LLM Contextë¥¼ ìƒì„±"""
        
        # ðŸš¨ ë™ì  Cypher ì¿¼ë¦¬ ìƒì„±
        # candidates_str = "['8541', '9405']" í˜•íƒœì˜ Cypher ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        candidates_str = str(candidate_codes).replace("'", '"')

        # LLMì´ ì§ì ‘ ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ëŒ€ì‹ , ì½”ë“œë¥¼ ì‚½ìž…í•˜ì—¬ ì‹¤í–‰
        # cypher_query = f"""
        # UNWIND {candidates_str} AS root_code_str
        # MATCH p = (root:HSItem {{code: root_code_str}})-[:HAS_CHILD*1..]->(n)
        # WHERE NOT (n)-[:HAS_CHILD]->()
        # RETURN nodes(p) AS Path_Nodes, relationships(p) AS Path_Relationships
        # """

        cypher_query = f"""
        UNWIND {candidates_str} AS root_code_str
        MATCH p = (root:HSItem {{code: root_code_str}})-[:HAS_CHILD*1..]->(n)
        WHERE NOT (n)-[:HAS_CHILD]->()
        RETURN nodes(p) AS Path_Nodes, relationships(p) AS Path_Relationships
        """
        
        results = self.graph.query(cypher_query)
        
        final_context = "# [ê²€ìƒ‰ëœ HS Code ê³„ì¸µ êµ¬ì¡° ë°ì´í„°]\n\n"
        
        # --- LLM Context ë¬¸ìžì—´ ë³€í™˜ ë¡œì§ ---
        for result in results:
            nodes = result['Path_Nodes']
            
            # 1. ì‹œê°ì  ê³„ì¸µ ê²½ë¡œ êµ¬ì„± (ê³ ê°ë‹˜ì˜ ì˜ˆì‹œ í˜•íƒœ)
            if not nodes: continue

            path_text = ""
            table_rows = []
            
            for i, node in enumerate(nodes):
                code = node['code']
                desc = node['description']
                
                # ê²½ë¡œ í…ìŠ¤íŠ¸ ìƒì„±
                if i == 0:
                    path_text += f"[ì‹œìž‘ ë…¸ë“œ: {code} ({desc})]\n"
                    level_desc = "ìƒìœ„ ë ˆë²¨"
                elif i == len(nodes) - 1:
                    path_text += f"    |--[:HAS_CHILD]-> [ìµœì¢… ë…¸ë“œ: {code} ({desc})]\n"
                    level_desc = "ìµœì¢… ë ˆë²¨"
                else:
                    path_text += f"    |--[:HAS_CHILD]-> [ì¤‘ê°„ ë…¸ë“œ: {code} ({desc})]\n"
                    level_desc = "ì¤‘ê°„ ë ˆë²¨"
                
                # í…Œì´ë¸” í–‰ ë°ì´í„° ìˆ˜ì§‘
                table_rows.append(f"| {code} | {desc} | {level_desc} |")
            
            # Contextì— ê²½ë¡œ ì¶”ê°€
            final_context += path_text + "\n"
            
            # 2. ì¶”ë¡  ìš”ì•½ í…Œì´ë¸” êµ¬ì„±
            final_context += "---"
            final_context += "\n[ì¶”ë¡  ìš”ì•½ í…Œì´ë¸”]\n"
            final_context += "| ì½”ë“œ | ì˜ë¬¸ í’ˆëª©ëª… | ê³„ì¸µ |\n"
            final_context += "|:---|:---|:---|\n"
            final_context += "\n".join(table_rows) + "\n\n"
        
        return final_context

    def get_10digit_codes_from_6digit(self, six_digit_codes: List[str]) -> str:
        """6ìžë¦¬ ì½”ë“œë“¤ì˜ í•˜ìœ„ 10ìžë¦¬ ì½”ë“œë§Œ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ
        
        Args:
            six_digit_codes: 6ìžë¦¬ HS ì½”ë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['9405.40', '9405.50'])
            
        Returns:
            str: 10ìžë¦¬ ì½”ë“œë“¤ì˜ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìžì—´
        """
        # 6ìžë¦¬ ì½”ë“œë¥¼ ì •ê·œí™” (ì  ìžˆëŠ” í˜•ì‹ê³¼ ì  ì—†ëŠ” í˜•ì‹ ëª¨ë‘ ì‹œë„)
        # Neo4jì— ì €ìž¥ëœ í˜•ì‹ì´ ì¼ê´€ë˜ì§€ ì•Šì„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ ë‘ í˜•ì‹ ëª¨ë‘ ì‹œë„
        normalized_codes = []
        for code in six_digit_codes:
            code_clean = code.replace('.', '').replace('-', '')
            if len(code_clean) == 6:
                # ì  ì—†ëŠ” í˜•ì‹ ì¶”ê°€ (ì˜ˆ: '842139')
                normalized_codes.append(code_clean)
                # ì  ìžˆëŠ” í˜•ì‹ë„ ì¶”ê°€ (ì˜ˆ: '8421.39')
                formatted = f"{code_clean[:4]}.{code_clean[4:6]}"
                if formatted not in normalized_codes:
                    normalized_codes.append(formatted)
            elif '.' in code:
                # ì´ë¯¸ ì ì´ ìžˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶”ê°€
                normalized_codes.append(code)
                # ì  ì—†ëŠ” í˜•ì‹ë„ ì¶”ê°€
                code_no_dot = code.replace('.', '').replace('-', '')
                if code_no_dot not in normalized_codes:
                    normalized_codes.append(code_no_dot)
        
        if not normalized_codes:
            return "# [10ìžë¦¬ HS Code í›„ë³´]\n\n(6ìžë¦¬ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.)\n"
        
        # ì¤‘ë³µ ì œê±°
        normalized_codes = list(set(normalized_codes))
        candidates_str = str(normalized_codes).replace("'", '"')
        
        # 6ìžë¦¬ ì½”ë“œì˜ ì§ì ‘ ìžì‹ ì¤‘ 10ìžë¦¬ ì½”ë“œë§Œ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
        # ë¦¬í”„ ë…¸ë“œ(ë” ì´ìƒ ìžì‹ì´ ì—†ëŠ” ë…¸ë“œ)ë§Œ ê°€ì ¸ì˜¨ í›„ Pythonì—ì„œ 10ìžë¦¬ í•„í„°ë§
        cypher_query = f"""
        UNWIND {candidates_str} AS parent_code_str
        MATCH (parent:HSItem {{code: parent_code_str}})-[:HAS_CHILD*1..]->(child:HSItem)
        WHERE NOT (child)-[:HAS_CHILD]->()
        RETURN DISTINCT parent.code AS parent_code, child.code AS child_code, child.description AS child_description
        ORDER BY parent.code, child.code
        """
        
        try:
            results = self.graph.query(cypher_query)
        except Exception as e:
            print(f"ê²½ê³ : 10ìžë¦¬ ì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return "# [10ìžë¦¬ HS Code í›„ë³´]\n\n(ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.)\n"
        
        if not results:
            return "# [10ìžë¦¬ HS Code í›„ë³´]\n\n(í•˜ìœ„ 10ìžë¦¬ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)\n"
        
        # Pythonì—ì„œ 10ìžë¦¬ ì½”ë“œë§Œ í•„í„°ë§ (ì  ì œê±° í›„ 10ìžë¦¬)
        parent_to_children = {}
        for result in results:
            parent = result.get('parent_code', '')
            child_code = str(result.get('child_code', ''))
            child_desc = result.get('child_description', '')
            
            # ì  ì œê±° í›„ 10ìžë¦¬ì¸ì§€ í™•ì¸
            code_clean = child_code.replace('.', '').replace('-', '')
            if len(code_clean) == 10:
                if parent not in parent_to_children:
                    parent_to_children[parent] = []
                parent_to_children[parent].append({
                    'code': child_code,
                    'description': child_desc
                })
        
        if not parent_to_children:
            return "# [10ìžë¦¬ HS Code í›„ë³´]\n\n(í•˜ìœ„ 10ìžë¦¬ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)\n"
        
        # ì»¨í…ìŠ¤íŠ¸ ë¬¸ìžì—´ ìƒì„±
        final_context = "# [10ìžë¦¬ HS Code í›„ë³´]\n\n"
        final_context += "ë‹¤ìŒì€ ì˜ˆì¸¡ëœ 6ìžë¦¬ ì½”ë“œë“¤ì˜ í•˜ìœ„ 10ìžë¦¬ ì½”ë“œ ëª©ë¡ìž…ë‹ˆë‹¤.\n\n"
        
        for parent_code, children in parent_to_children.items():
            final_context += f"## ë¶€ëª¨ ì½”ë“œ: {parent_code}\n\n"
            final_context += "| 10ìžë¦¬ ì½”ë“œ | ì˜ë¬¸ í’ˆëª©ëª… |\n"
            final_context += "|:---|:---|\n"
            
            for child in children:
                code = child['code']
                desc = child['description']
                final_context += f"| {code} | {desc} |\n"
            
            final_context += "\n"
        
        return final_context

    def get_6digit_codes_from_4digit(self, four_digit_codes: List[str]) -> str:
        """4ìžë¦¬ ì½”ë“œë“¤ì˜ í•˜ìœ„ 6ìžë¦¬ ì½”ë“œë§Œ ë°˜í™˜í•˜ëŠ” ë©”ì„œë“œ
        
        Args:
            four_digit_codes: 4ìžë¦¬ HS ì½”ë“œ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['9405', '9406'])
            
        Returns:
            str: 6ìžë¦¬ ì½”ë“œë“¤ì˜ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìžì—´
        """
        # 4ìžë¦¬ ì½”ë“œë¥¼ ì •ê·œí™”
        normalized_codes = []
        for code in four_digit_codes:
            # ì  ì œê±° í›„ 4ìžë¦¬ í™•ì¸
            code_clean = code.replace('.', '').replace('-', '')
            if len(code_clean) == 4:
                normalized_codes.append(code_clean)
            elif '.' in code:
                # 'XXXX' í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                code_clean = code.split('.')[0].replace('-', '')
                if len(code_clean) == 4:
                    normalized_codes.append(code_clean)
        
        if not normalized_codes:
            return "# [6ìžë¦¬ HS Code í›„ë³´]\n\n(4ìžë¦¬ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.)\n"
        
        candidates_str = str(normalized_codes).replace("'", '"')
        
        # 4ìžë¦¬ ì½”ë“œì˜ ì§ì ‘ ìžì‹ ì¤‘ 6ìžë¦¬ ì½”ë“œë§Œ ê°€ì ¸ì˜¤ëŠ” ì¿¼ë¦¬
        # ë¦¬í”„ ë…¸ë“œê°€ ì•„ë‹Œ 6ìžë¦¬ ì½”ë“œë§Œ ê°€ì ¸ì˜´
        cypher_query = f"""
        UNWIND {candidates_str} AS parent_code_str
        MATCH (parent:HSItem {{code: parent_code_str}})-[:HAS_CHILD*1..]->(child:HSItem)
        WHERE (child)-[:HAS_CHILD]->()
        RETURN DISTINCT parent.code AS parent_code, child.code AS child_code, child.description AS child_description
        ORDER BY parent.code, child.code
        """
        
        try:
            results = self.graph.query(cypher_query)
        except Exception as e:
            print(f"ê²½ê³ : 6ìžë¦¬ ì½”ë“œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return "# [6ìžë¦¬ HS Code í›„ë³´]\n\n(ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.)\n"
        
        if not results:
            return "# [6ìžë¦¬ HS Code í›„ë³´]\n\n(í•˜ìœ„ 6ìžë¦¬ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)\n"
        
        # Pythonì—ì„œ 6ìžë¦¬ ì½”ë“œë§Œ í•„í„°ë§ (ì  ì œê±° í›„ 6ìžë¦¬, ìžì‹ì´ ìžˆëŠ” ë…¸ë“œ)
        parent_to_children = {}
        for result in results:
            parent = result.get('parent_code', '')
            child_code = result.get('child_code', '')
            child_desc = result.get('child_description', '')
            
            # ì  ì œê±° í›„ 6ìžë¦¬ì¸ì§€ í™•ì¸
            code_clean = child_code.replace('.', '').replace('-', '')
            if len(code_clean) == 6:
                if parent not in parent_to_children:
                    parent_to_children[parent] = []
                parent_to_children[parent].append({
                    'code': child_code,
                    'description': child_desc
                })
        
        if not parent_to_children:
            return "# [6ìžë¦¬ HS Code í›„ë³´]\n\n(í•˜ìœ„ 6ìžë¦¬ ì½”ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.)\n"
        
        # ì»¨í…ìŠ¤íŠ¸ ë¬¸ìžì—´ ìƒì„±
        final_context = "# [6ìžë¦¬ HS Code í›„ë³´]\n\n"
        final_context += "ë‹¤ìŒì€ ì˜ˆì¸¡ëœ 4ìžë¦¬ ì½”ë“œë“¤ì˜ í•˜ìœ„ 6ìžë¦¬ ì½”ë“œ ëª©ë¡ìž…ë‹ˆë‹¤.\n\n"
        
        for parent_code, children in parent_to_children.items():
            final_context += f"## ë¶€ëª¨ ì½”ë“œ: {parent_code}\n\n"
            final_context += "| 6ìžë¦¬ ì½”ë“œ | ì˜ë¬¸ í’ˆëª©ëª… |\n"
            final_context += "|:---|:---|\n"
            
            for child in children:
                code = child['code']
                desc = child['description']
                final_context += f"| {code} | {desc} |\n"
            
            final_context += "\n"
        
        return final_context

    def generate_recommendation(self, user_input: str):
        """LLMì„ ì‚¬ìš©í•˜ì—¬ HS Code ì¶”ì²œ ìƒì„±"""
        # 1. Context ê²€ìƒ‰
        context = self.get_graph_context(self.get_vector_candidates(user_input))
        # 2. LLM Prompt êµ¬ì„±
        template = """
        ë‹¹ì‹ ì€ HS Code ì¶”ì²œ ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. 
        ì œê³µëœ [ê²€ìƒ‰ëœ HS Code ê³„ì¸µ êµ¬ì¡° ë°ì´í„°] ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìžì˜ ìƒí’ˆì— ê°€ìž¥ ì í•©í•œ 10ìžë¦¬ HS Codeë¥¼ ì¶”ì²œí•˜ê³ , 
        ì™œ ê·¸ ì½”ë“œë¥¼ ì„ íƒí–ˆëŠ”ì§€ ê³„ì¸µ ê²½ë¡œë¥¼ ì„¤ëª…í•˜ì‹­ì‹œì˜¤. 
        ë§Œì•½ ì—¬ëŸ¬ ê²½ë¡œê°€ ê²€ìƒ‰ë˜ì—ˆë‹¤ë©´, ëª¨ë“  ê²½ë¡œë¥¼ ì œì‹œí•˜ê³  ìµœì¢… ì„ íƒì„ ì‚¬ìš©ìžì—ê²Œ ë§¡ê¸°ì‹­ì‹œì˜¤.

        ì‚¬ìš©ìž ìƒí’ˆ: {user_input}

        [ê²€ìƒ‰ëœ HS Code ê³„ì¸µ êµ¬ì¡° ë°ì´í„°]:
        {context}
        """
        
        prompt = ChatPromptTemplate.from_template(template)
        
        # 3. LLM Chain ì‹¤í–‰
        chain = prompt | ChatOpenAI(model="gpt-4-turbo") 
        
        response = chain.invoke({"user_input": user_input, "context": context})
        
        return response.content

    def get_final_context(self, user_input: str, k: int = 5) -> str:
        """
        ë‹¤ë¥¸ íŒŒì¼ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìžˆëŠ” ë©”ì¸ ë©”ì„œë“œ
        Inputê³¼ kë¥¼ ë°›ì•„ì„œ ê°€ìž¥ ê°€ê¹Œìš´ Top-k í›„ë³´ì˜ final_contextë¥¼ ë°˜í™˜
        
        Args:
            user_input (str): ì‚¬ìš©ìž ìž…ë ¥ (ìƒí’ˆëª… ë“±)
            k (int): ê²€ìƒ‰í•  í›„ë³´ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
            
        Returns:
            str: ê²€ìƒ‰ëœ HS Code ê³„ì¸µ êµ¬ì¡° ë°ì´í„°ì˜ final_context
        """
        # 1. Vector Searchë¡œ í›„ë³´ ì½”ë“œ ê²€ìƒ‰
        candidate_codes = self.get_vector_candidates(user_input, k)
        
        # 2. í›„ë³´ ì½”ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì¸µ êµ¬ì¡° Context ìƒì„±
        final_context = self.get_graph_context(candidate_codes)
        
        return final_context


# ì‚¬ìš© ì˜ˆì‹œ (ë‹¤ë¥¸ íŒŒì¼ì—ì„œ importí•  ë•ŒëŠ” ì´ ë¶€ë¶„ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ)
if __name__ == "__main__":
    # GraphRAG ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    graph_rag = GraphRAG()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("=== GraphRAG í…ŒìŠ¤íŠ¸ ===")
    result = graph_rag.get_final_context("ë°©ë¶€ì²˜ë¦¬í•œ ì ì†¡ ë‚˜ë¬´", k=5)
    print(result)


# final_context = graph_rag.get_final_context(user_input, k) -> context ë°˜í™˜

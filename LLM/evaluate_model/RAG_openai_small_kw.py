# RAG_openai_small_kw.py
# -*- coding: utf-8 -*-
"""
- ë„¤ê°€ ì¤€ classify_hs_code() í˜•íƒœë¥¼ RAGë¡œ í™•ì¥í•œ ë²„ì „
- Chroma Persistent DB(=chromadb í´ë”) ì—°ë™
- ì¸ë±ì‹± ë•Œ ì‚¬ìš©í•œ ì„ë² ë”© ëª¨ë¸ê³¼ ë™ì¼ ëª¨ë¸ ì‚¬ìš©(ì¤‘ìš”!)
- LLMì€ JSON ëª¨ë“œ(response_format={"type":"json_object"})ë¡œ ê°•ì œ
- ì„ë² ë”© ëª¨ë¸ ë³€ê²½: intfloat/multilingual-e5-small
"""

from openai import OpenAI
from dotenv import load_dotenv
import os, re, json
from typing import List, Dict, Any, Tuple
from konlpy.tag import Okt
import sys
import os
# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ì—ì„œ ìƒìœ„ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ í›„ RAG_embedding í´ë” ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
rag_embedding_dir = os.path.join(parent_dir, 'RAG_embedding')

sys.path.append(rag_embedding_dir)
from graph_rag import GraphRAG

# ===== 0) í™˜ê²½ì„¤ì • =====
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Chroma ì„¤ì •(í´ë” ê²½ë¡œ = chroma.sqlite3ê°€ ë“¤ì–´ìˆëŠ” ë””ë ‰í„°ë¦¬)
CHROMA_DIR = os.getenv("CHROMA_DIR", r"../chroma_db_openai_small_kw")  # ì˜ˆ: C:\...\embedding\chroma_db
COLLECTION_NAME = os.getenv("CHROMA_COLLECTION", "hscode_collection")

# ì¸ë±ì‹± ë•Œ ì¼ë˜ ì„ë² ë”© ëª¨ë¸ê³¼ ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ!
EMBED_MODEL = os.getenv("EMBED_MODEL", "text-embedding-3-small") # ëª¨ë¸ ë³€ê²½!

okt_analyzer = Okt()
STOPWORDS = [
    'ì˜', 'ê°€', 'ì´', 'ì€', 'ë“¤', 'ëŠ”', 'ì¢€', 'ì˜', 'ê±', 'ê³¼', 'ë„', 'ë¥¼', 'ìœ¼ë¡œ', 'ì', 'ì—', 'ì™€', 'í•œ', 'í•˜ë‹¤',
    'ìƒí’ˆëª…', 'ì„¤ëª…', 'ì‚¬ìœ ', 'ì´ë¦„', 'ì œí’ˆ', 'ê´€ë ¨', 'ë‚´ìš©', 'í•­ëª©', 'ë¶„ë¥˜', 'ê¸°ì¤€',
    'hs', 'code', 'item', 'des', 'description', 'name'
]
def extract_keywords_advanced(text: str) -> str:
    """ì‚¬ìš©ì ì…ë ¥ì„ DBì™€ ë™ì¼í•œ 'í‚¤ì›Œë“œ' í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    
    # (1ë‹¨ê³„(ì¸ë±ì‹±)ì—ì„œ ì“´ ë¡œì§ê³¼ 100% ë™ì¼í•´ì•¼ í•¨)
    tagged_words = okt_analyzer.pos(text, norm=True, stem=False)
    keywords = []

    for word, tag in tagged_words:
        if tag in ['Noun', 'Alpha']:
            keywords.append(word)
    regex_keywords = re.findall(r'\b[a-zA-Z0-9]{2,}\b', text)
    keywords.extend(regex_keywords)
    filtered_keywords = set() 

    for k in keywords:
        k_lower = k.lower() 
        if len(k) > 1 and k_lower not in STOPWORDS:
            filtered_keywords.add(k)

    return " ".join(sorted(list(filtered_keywords)))
    
  

# ===== 1) ì•ˆì „ JSON íŒŒì„œ(ë„¤ ì½”ë“œ ê·¸ëŒ€ë¡œ) =====
def _parse_json_safely(text: str):
    """
    1) ê·¸ëŒ€ë¡œ json.loads ì‹œë„
    2) ```json ... ``` ë˜ëŠ” ``` ... ``` ê°ì‹¸ì§„ ê²½ìš° ë²—ê²¨ì„œ ì¬ì‹œë„
    3) ë§ˆì§€ë§‰ìœ¼ë¡œ ì¤‘ê´„í˜¸/ëŒ€ê´„í˜¸ ë²”ìœ„ë§Œ ì¶”ì¶œí•´ì„œ ì¬ì‹œë„
    """
    try:
        return json.loads(text), None
    except json.JSONDecodeError:
        pass

    # ì½”ë“œíœìŠ¤ ì œê±°
    fenced = re.sub(r"^```[a-zA-Z]*\s*|\s*```$", "", text.strip(), flags=re.DOTALL)
    try:
        return json.loads(fenced), None
    except json.JSONDecodeError:
        pass

    # JSON ìŠ¤ë‹ˆí«ë§Œ ì¶”ì¶œ (ê°€ì¥ ë°”ê¹¥ { ... } ë˜ëŠ” [ ... ])
    m = re.search(r"(\{.*\}|\[.*\])", text, flags=re.DOTALL)
    if m:
        try:
            return json.loads(m.group(1)), None
        except json.JSONDecodeError as e:
            return None, f"JSON decode failed after extraction: {e}"
    return None, "JSON decode failed: unrecognized format"


# ===== 2) ì„ë² ë”© & Chroma ìœ í‹¸ =====
# from sentence_transformers import SentenceTransformer
import numpy as np
import chromadb
from chromadb.config import Settings
from langchain_openai import OpenAIEmbeddings

class QueryEmbedder:
    def __init__(self, model_name: str = EMBED_MODEL, device: str = "cpu"):
        self.model = OpenAIEmbeddings(
            model=model_name,
            openai_api_key=os.getenv("OPENAI_API_KEY") # API í‚¤ ëª…ì‹œì  ì „ë‹¬ (ì•ˆì •ì„± í–¥ìƒ)
        )
        self.normalize = True

    def embed(self, texts: List[str]) -> np.ndarray:
        # ğŸŒŸ LangChainì˜ embed_documents ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ê³„ì‚°
        vecs = self.model.embed_documents(texts)
        # ê²°ê³¼ëŠ” List[List[float]] í˜•íƒœì´ë¯€ë¡œ, numpy ë°°ì—´ë¡œ ë³€í™˜
        return np.asarray(vecs, dtype="float32")

def open_chroma_collection(persist_dir: str, collection_name: str):
    client = chromadb.PersistentClient(path=persist_dir, settings=Settings(anonymized_telemetry=False))
    try:
        return client.get_collection(name=collection_name)
    except Exception:
        names = [c.name for c in client.list_collections()]
        raise RuntimeError(f"ì»¬ë ‰ì…˜ '{collection_name}' ì—†ìŒ. í˜„ì¬ ì»¬ë ‰ì…˜ë“¤: {names}")


def search_chroma(collection, embedder, query_text: str, top_k: int = 12):
    qvec = embedder.embed([query_text])[0]

    # âŒ includeì— "ids" ë„£ì§€ ë§ˆì„¸ìš”
    res = collection.query(
        query_embeddings=[qvec.tolist()],
        n_results=top_k,
        include=["documents", "metadatas", "distances", "embeddings"],  # â† ì—¬ê¸°ì„œ ìˆ˜ì •
    )

    # idsëŠ” includeì— ì—†ì–´ë„ ê¸°ë³¸ìœ¼ë¡œ ë‚´ë ¤ì˜µë‹ˆë‹¤.
    ids      = (res.get("ids") or [[]])[0]
    dists    = (res.get("distances") or [[]])[0]
    docs_txt = (res.get("documents") or [[]])[0]
    metas    = (res.get("metadatas") or [[]])[0]
    embeds   = (res.get("embeddings") or [[]])[0]

    docs = []
    for id_, dist, txt, meta, emb in zip(ids, dists, docs_txt, metas, embeds):
        docs.append({
            "id": id_,
            "distance": float(dist),
            "document": txt,
            "metadata": meta,
            # ì´í›„ MMR ë“±ì—ì„œ ì“°ë ¤ë©´ ë²¡í„°ë„ ë³´ê´€
            "embedding": np.asarray(emb, dtype="float32")
        })

    # ê±°ë¦¬(ì‘ì„ìˆ˜ë¡ ìœ ì‚¬) ê¸°ì¤€ ì •ë ¬
    docs.sort(key=lambda d: d["distance"])
    return docs



# ===== 3) RAG í”„ë¡¬í”„íŠ¸ ë¹Œë” =====
def build_rag_prompt(product_name: str, product_description: str, retrieved: List[Dict[str, Any]], top_n: int, graph_context: str = "") -> Tuple[str, str]:
    """
    - system: ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œë§Œ ë‹µí•˜ë„ë¡ ê°€ë“œ
    - user: ì§ˆë¬¸ + ì»¨í…ìŠ¤íŠ¸ + JSON ìŠ¤í‚¤ë§ˆ(ì—„ê²©)
    """
    system = (
        "ë‹¹ì‹ ì€ êµ­ì œë¬´ì—­ HS ì½”ë“œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
        "ê·œì¹™:\n"
        "1) ì œê³µëœ context ë‚´ì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ íŒë‹¨í•©ë‹ˆë‹¤.\n"
        "2) HS Code ê³„ì¸µ êµ¬ì¡°(GraphDB Context)ëŠ” ì „ì²´ HS Code dataì´ë©°\n"
        "   í’ˆëª©ë¶„ë¥˜ì‚¬ë¡€(VectorDB Context)ëŠ” classify Case dataì…ë‹ˆë‹¤.\n"
        "3) ê³„ì¸µ êµ¬ì¡°ì™€ ë‹¤ë¥¸ ì½”ë“œëŠ” ì ˆëŒ€ ì œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
        "4) ì¶”ì²œí•˜ëŠ” HS CodeëŠ” ë°˜ë“œì‹œ 10ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.\n"
        "5) í•­ìƒ ì‘ë‹µì€ strict JSON formatìœ¼ë¡œë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
        "6) í™•ì‹ ì´ ì—†ì„ ê²½ìš° 'candidates': [] ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤."
    )

    # ===== ì—¬ê¸°ë¶€í„° ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡ êµ¬ì„± ë¶€ë¶„ë§Œ ìš”ì²­í•œ ë°©ì‹ìœ¼ë¡œ êµì²´ =====
    def _pick(meta, keys, default=""):
        for k in keys:
            v = meta.get(k)
            if v not in (None, ""):
                return str(v)
        return default

    def _fallback_name_from_body(body: str) -> str:
        # ë³¸ë¬¸ ì²« ì¤„ì— "ìƒí’ˆëª…: ..." íŒ¨í„´ì´ ìì£¼ ìˆìœ¼ë¯€ë¡œ ê±°ê¸°ì„œ ë³´ì • ì¶”ì¶œ
        m = re.search(r"^ìƒí’ˆëª…:\s*(.+)$", body, flags=re.MULTILINE)
        return m.group(1).strip() if m else ""

    # ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡(ìµœëŒ€ 6~10ê°œ ê¶Œì¥)
    blocks = []
    for d in retrieved[:10]:
        meta = d.get("metadata", {}) or {}
        body = (d.get("document") or "").strip()

        # 1) ë©”íƒ€ ê¸°ì¤€(ì‹¤ì¸¡ í‚¤ì— ë§ì¶¤) + 2) ë³¸ë¬¸ ë³´ì • ì¶”ì¶œ
        hs   = _pick(meta, ["HSCode", "hs_code", "HS", "HSë¶€í˜¸"])
        name = _pick(meta, ["ìƒí’ˆëª…", "í•œê¸€í’ˆëª©ëª…", "title", "í’ˆëª©ëª…"]) or _fallback_name_from_body(body)
        date = _pick(meta, ["ì‹œí–‰ì¼ì", "ë°œí–‰ì¼"])

        # ì„ íƒ: body ê¸¸ì´ ì•ˆì „ ì ˆë‹¨
        max_chars = 1200
        if len(body) > max_chars:
            body = body[:max_chars] + "â€¦"

        # distancesëŠ” query() ì‚¬ìš© ì‹œì—ë§Œ ì¡´ì¬. get()ì´ë©´ ì—†ìŒ â†’ 0.0
        dist = d.get("distance", 0.0)
        try:
            dist = float(dist)
        except Exception:
            dist = 0.0

        blocks.append(
            f"[DOC id={d.get('id')} dist={dist:.4f}]\n"
            f"ìƒí’ˆëª…: {name}\nHSCode: {hs}\nì‹œí–‰ì¼ì: {date}\në³¸ë¬¸:\n{body}\n"
        )

    vector_context = "\n\n".join(blocks) if blocks else "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"
    # ===== êµì²´ ë =====

    # GraphDB context ì¶”ê°€
    graph_section = ""
    if graph_context.strip():
        graph_section = f"{graph_context}"
    else:
        graph_section = "(GraphDB ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"

    user = f"""
ë‹¤ìŒ ì œí’ˆì˜ HS ì½”ë“œ ìƒìœ„ {top_n} í›„ë³´ë¥¼ ì¶”ì²œí•˜ì„¸ìš”. 
**ì¤‘ìš”: ì¶”ì²œí•˜ëŠ” ëª¨ë“  HS CodeëŠ” ë°˜ë“œì‹œ 10ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: 9405.40.10.00).**

[ì…ë ¥]
- Product Name: {product_name}
- Product Description: {product_description}

================================================
[context]
[HS Code ê³„ì¸µ êµ¬ì¡° Context â€” GraphDB Retrieved]
(ëª¨ë“  ë°ì´í„°ëŠ” HS ê³µì‹ nomenclature ê¸°ë°˜)
{graph_section}
================================================

[í’ˆëª©ë¶„ë¥˜ì‚¬ë¡€ Context â€” VectorDB Retrieved]
(ì •ë¶€ í’ˆëª©ë¶„ë¥˜ì‚¬ë¡€ ë¬¸ì„œ ê¸°ë°˜ ê·¼ê±° ìë£Œ)
{vector_context}  
================================================

[ì‘ë‹µ í˜•ì‹: strict JSON â€” ì¶”ê°€ í‚¤ ê¸ˆì§€]
{{
  "candidates": [
    {{
      "hs_code": "string",          // ë°˜ë“œì‹œ 10ìë¦¬ HS Code (ì˜ˆ: 9405.40.10.00)
      "title": "string",
      "reason": "string",           // í•œêµ­ì–´, 200ì ì´ë‚´
      "citations": [
        {{"type": "graph", "code": "string"}},   // GraphDB ê·¼ê±°
        {{"type": "case", "doc_id": "string"}}   // VectorDB ê·¼ê±°
      ]
    }}
  ]
}}

í•„ìˆ˜ ê·œì¹™:
1) í›„ë³´ëŠ” ìµœëŒ€ {top_n}ê°œ.
2) hs_codeëŠ” ë°˜ë“œì‹œ 10ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: 9405.40.10.00).
3) citationsëŠ” ìµœì†Œ 1ê°œ ì´ìƒ í¬í•¨.
4) citations.typeì€ ë°˜ë“œì‹œ "graph" ë˜ëŠ” "case"ë§Œ ê°€ëŠ¥.
"""
    return system, user


# ===== 4) ìµœì¢… í•¨ìˆ˜: RAG + JSON ëª¨ë“œ =====
def classify_hs_code_rag(product_name: str, product_description: str, top_n: int = 3) -> Dict[str, Any]:
    """
    1) Chromaì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    2) GraphRAGì—ì„œ ê³„ì¸µ êµ¬ì¡° ì •ë³´ ê²€ìƒ‰
    3) ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ LLM(JSON ê°•ì œ) í˜¸ì¶œ
    4) JSON íŒŒì‹±í•´ ë°˜í™˜
    """
    # 1) Chroma ê²€ìƒ‰
    emb = QueryEmbedder(EMBED_MODEL)
    col = open_chroma_collection(CHROMA_DIR, COLLECTION_NAME)
    original_query_text = f"{product_name}\n{product_description}"
    keyword_query_text = extract_keywords_advanced(original_query_text)
    # keyword_query_text = original_query_text
    hits = search_chroma(col, emb, keyword_query_text, top_k=max(8, top_n*3))

    # 2) GraphRAGì—ì„œ ê³„ì¸µ êµ¬ì¡° ì •ë³´ ê²€ìƒ‰
    try:
        graph_rag = GraphRAG()
        graph_context = graph_rag.get_final_context(original_query_text, k=5)
    except Exception as e:
        print(f"GraphRAG ì˜¤ë¥˜: {e}")
        graph_context = ""

    # 3) í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    sys_prompt, user_prompt = build_rag_prompt(product_name, product_description, hits, top_n, graph_context)

    # 4) JSON ëª¨ë“œ í˜¸ì¶œ
    response = client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user",   "content": user_prompt}
        ],
        temperature=0.2,
        response_format={"type": "json_object"},  # <- í•µì‹¬: ìˆœìˆ˜ JSONë§Œ ë°˜í™˜
        timeout=120
    )

    output_text = response.choices[0].message.content.strip()

    # 5) ì•ˆì „ íŒŒì‹±
    result, err = _parse_json_safely(output_text)
    if err:
        result = {"error": err, "raw_output": output_text}

    return result


# ===== 5) GraphRAG í†µí•© í—¬í¼ í•¨ìˆ˜ =====
def get_enhanced_context(product_name: str, product_description: str, k: int = 5) -> Dict[str, str]:
    """
    ChromaDBì™€ GraphDBì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        product_name: ìƒí’ˆëª…
        product_description: ìƒí’ˆì„¤ëª…
        k: GraphDBì—ì„œ ê²€ìƒ‰í•  í›„ë³´ ê°œìˆ˜
        
    Returns:
        Dict[str, str]: chroma_contextì™€ graph_contextë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    # ChromaDB ì»¨í…ìŠ¤íŠ¸
    emb = QueryEmbedder(EMBED_MODEL)
    col = open_chroma_collection(CHROMA_DIR, COLLECTION_NAME)
    original_query_text = f"{product_name}\n{product_description}"
    # keyword_query_text = extract_keywords_advanced(original_query_text)
    keyword_query_text = original_query_text
    hits = search_chroma(col, emb, keyword_query_text, top_k=8)
    
    # ChromaDB ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    def _pick(meta, keys, default=""):
        for k in keys:
            v = meta.get(k)
            if v not in (None, ""):
                return str(v)
        return default

    def _fallback_name_from_body(body: str) -> str:
        m = re.search(r"^ìƒí’ˆëª…:\s*(.+)$", body, flags=re.MULTILINE)
        return m.group(1).strip() if m else ""

    blocks = []
    for d in hits[:10]:
        meta = d.get("metadata", {}) or {}
        body = (d.get("document") or "").strip()

        hs   = _pick(meta, ["HSCode", "hs_code", "HS", "HSë¶€í˜¸"])
        name = _pick(meta, ["ìƒí’ˆëª…", "í•œê¸€í’ˆëª©ëª…", "title", "í’ˆëª©ëª…"]) or _fallback_name_from_body(body)
        date = _pick(meta, ["ì‹œí–‰ì¼ì", "ë°œí–‰ì¼"])

        max_chars = 1200
        if len(body) > max_chars:
            body = body[:max_chars] + "â€¦"

        dist = d.get("distance", 0.0)
        try:
            dist = float(dist)
        except Exception:
            dist = 0.0

        blocks.append(
            f"[DOC id={d.get('id')} dist={dist:.4f}]\n"
            f"ìƒí’ˆëª…: {name}\nHSCode: {hs}\nì‹œí–‰ì¼ì: {date}\në³¸ë¬¸:\n{body}\n"
        )

    chroma_context = "\n\n".join(blocks) if blocks else "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"
    
    # GraphDB ì»¨í…ìŠ¤íŠ¸
    try:
        graph_rag = GraphRAG()
        graph_context = graph_rag.get_final_context(original_query_text, k=k)
    except Exception as e:
        print(f"GraphRAG ì˜¤ë¥˜: {e}")
        graph_context = ""
    
    return {
        "vector_context": chroma_context,
        "graph_context": graph_context,
        "query_text": original_query_text
    }


# ===== 6) ì˜ˆì‹œ ì‹¤í–‰ =====
if __name__ == "__main__":
    print("=== í†µí•© RAG í…ŒìŠ¤íŠ¸ (ChromaDB + GraphDB) ===")
    name = "LED ì¡°ëª…"
    desc = "í”Œë¼ìŠ¤í‹± í•˜ìš°ì§•ì— ì¥ì°©ëœ LED ì¡°ëª… ëª¨ë“ˆë¡œ, ì‹¤ë‚´ìš© ì¡°ëª… ê¸°êµ¬"
    
    print(f"ìƒí’ˆëª…: {name}")
    print(f"ìƒí’ˆì„¤ëª…: {desc}")
    print("\nì²˜ë¦¬ ì¤‘...")
    
    # 1. ê°œë³„ ì»¨í…ìŠ¤íŠ¸ í™•ì¸
    print("\n=== 1. ì»¨í…ìŠ¤íŠ¸ í™•ì¸ ===")
    contexts = get_enhanced_context(name, desc, k=5)
    print(f"VectorDB ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(contexts['vector_context'])}")
    print(f"GraphDB ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(contexts['graph_context'])}")
    
    # 2. í†µí•© RAG ì‹¤í–‰
    print("\n=== 2. í†µí•© RAG ì‹¤í–‰ ===")
    out = classify_hs_code_rag(name, desc, top_n=3)
    print("\n=== ìµœì¢… ê²°ê³¼ ===")
    print(json.dumps(out, ensure_ascii=False, indent=2))

# python LLM/RAG.py

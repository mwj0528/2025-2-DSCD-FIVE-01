import streamlit as st
import os, sys, re, json
import uuid

st.set_page_config(page_title="HS Code ì¶”ì²œê¸° ğŸ¤–", layout="centered")

from openai import OpenAI
from dotenv import load_dotenv
import os, re, json
from typing import List, Dict, Any, Tuple
from konlpy.tag import Okt
import sys
import os
import streamlit as st
#########

import sys
import os
# 1. ì´ íŒŒì¼(rag_hs_prompt.py)ì˜ í˜„ì¬ ê²½ë¡œë¥¼ ì°¾ìŒ
#    -> /home/oohga/project/LLM
current_dir = os.path.dirname(os.path.abspath(__file__))

# 2. ê·¸ê²ƒì˜ 'ë¶€ëª¨ í´ë”'(project) ê²½ë¡œë¥¼ ì°¾ìŒ
#    -> /home/oohga/project
parent_dir = os.path.dirname(current_dir)

# 3. Pythonì´ 'ë¶€ëª¨ í´ë”'ë¥¼ ê²€ìƒ‰í•˜ë„ë¡ ê²½ë¡œ(sys.path)ì— ì¶”ê°€
sys.path.append(parent_dir)

# --- (ì´ì œì„œì•¼ Pythonì´ 'project/' í´ë”ë¥¼ ë’¤ì§€ê¸° ì‹œì‘í•¨) ---

# 4. ì´ì œ Pythonì´ 'RAG_embedding' í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŒ
from RAG_embedding.graph_rag import GraphRAG


#################

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ì—ì„œ ìƒìœ„ ë””ë ‰í† ë¦¬ë¡œ ì´ë™ í›„ RAG_embedding í´ë” ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
rag_embedding_dir = os.path.join(parent_dir, 'RAG_embedding')

sys.path.append(rag_embedding_dir)
from RAG_embedding.graph_rag import GraphRAG

# ===== 0) í™˜ê²½ì„¤ì • =====
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Chroma ì„¤ì •(í´ë” ê²½ë¡œ = chroma.sqlite3ê°€ ë“¤ì–´ìˆëŠ” ë””ë ‰í„°ë¦¬)
CHROMA_DIR = '/home/oohga/project/LLM/chroma_db'  # ì˜ˆ: C:\...\embedding\chroma_db
COLLECTION_NAME = "hscode_collection"

# ì¸ë±ì‹± ë•Œ ì¼ë˜ ì„ë² ë”© ëª¨ë¸ê³¼ ë°˜ë“œì‹œ ë™ì¼í•˜ê²Œ!
EMBED_MODEL = os.getenv("EMBED_MODEL", "paraphrase-multilingual-MiniLM-L12-v2")

okt_analyzer = Okt()
STOPWORDS = [
    'ì˜', 'ê°€', 'ì´', 'ì€', 'ë“¤', 'ëŠ”', 'ì¢€', 'ì˜', 'ê±', 'ê³¼', 'ë„', 'ë¥¼', 'ìœ¼ë¡œ', 'ì', 'ì—', 'ì™€', 'í•œ', 'í•˜ë‹¤',
    'ìƒí’ˆëª…', 'ì„¤ëª…', 'ì‚¬ìœ ', 'ì´ë¦„', 'ì œí’ˆ', 'ê´€ë ¨', 'ë‚´ìš©', 'í•­ëª©', 'ë¶„ë¥˜', 'ê¸°ì¤€',
    'hs', 'code', 'item', 'des', 'description', 'name'
]
def extract_keywords_advanced(text: str) -> str:
    """ì‚¬ìš©ì ì…ë ¥ì„ DBì™€ ë™ì¼í•œ 'í‚¤ì›Œë“œ' í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    
    # (1ë‹¨ê³„(ì¸ë±ì‹±)ì—ì„œ ì“´ ë¡œì§ê³¼ 100% ë™ì¼í•´ì•¼ í•¨)
    tagged_words = okt_analyzer.pos(text, norm=True, stem=False)
    keywords = []

    for word, tag in tagged_words:
        if tag in ['Noun', 'Alpha']:
            keywords.append(word)
    regex_keywords = re.findall(r'\b[a-zA-Z0-9]{2,}\b', text)
    keywords.extend(regex_keywords)
    filtered_keywords = set() 

    for k in keywords:
        k_lower = k.lower() 
        if k_lower not in STOPWORDS:
            filtered_keywords.add(k)

    return " ".join(sorted(list(filtered_keywords)))
    
  

# ===== 1) ì•ˆì „ JSON íŒŒì„œ(ë„¤ ì½”ë“œ ê·¸ëŒ€ë¡œ) =====
def _parse_json_safely(text: str):
    """
    1) ê·¸ëŒ€ë¡œ json.loads ì‹œë„
    2) ```json ... ``` ë˜ëŠ” ``` ... ``` ê°ì‹¸ì§„ ê²½ìš° ë²—ê²¨ì„œ ì¬ì‹œë„
    3) ë§ˆì§€ë§‰ìœ¼ë¡œ ì¤‘ê´„í˜¸/ëŒ€ê´„í˜¸ ë²”ìœ„ë§Œ ì¶”ì¶œí•´ì„œ ì¬ì‹œë„
    """
    try:
        return json.loads(text), None
    except json.JSONDecodeError:
        pass

    # ì½”ë“œíœìŠ¤ ì œê±°
    fenced = re.sub(r"^```[a-zA-Z]*\s*|\s*```$", "", text.strip(), flags=re.DOTALL)
    try:
        return json.loads(fenced), None
    except json.JSONDecodeError:
        pass

    # JSON ìŠ¤ë‹ˆí«ë§Œ ì¶”ì¶œ (ê°€ì¥ ë°”ê¹¥ { ... } ë˜ëŠ” [ ... ])
    m = re.search(r"(\{.*\}|\[.*\])", text, flags=re.DOTALL)
    if m:
        try:
            return json.loads(m.group(1)), None
        except json.JSONDecodeError as e:
            return None, f"JSON decode failed after extraction: {e}"
    return None, "JSON decode failed: unrecognized format"


# ===== 2) ì„ë² ë”© & Chroma ìœ í‹¸ =====
from sentence_transformers import SentenceTransformer
import numpy as np
import chromadb
from chromadb.config import Settings

class QueryEmbedder:
    def __init__(self, model_name: str = EMBED_MODEL, device: str = "cpu"):
        self.model = SentenceTransformer(model_name, device=device)
        self.normalize = True

    def embed(self, texts: List[str]) -> np.ndarray:
        vecs = self.model.encode(
            texts,
            batch_size=32,
            show_progress_bar=False,
            normalize_embeddings=self.normalize
        )
        return np.asarray(vecs, dtype="float32")

def open_chroma_collection(persist_dir: str, collection_name: str):
    client = chromadb.PersistentClient(path=persist_dir, settings=Settings(anonymized_telemetry=False))
    try:
        return client.get_collection(name=collection_name)
    except Exception:
        names = [c.name for c in client.list_collections()]
        raise RuntimeError(f"ì»¬ë ‰ì…˜ '{collection_name}' ì—†ìŒ. í˜„ì¬ ì»¬ë ‰ì…˜ë“¤: {names}")


def search_chroma(collection, embedder, query_text: str, top_k: int = 12):
    qvec = embedder.embed([query_text])[0]

    # âŒ includeì— "ids" ë„£ì§€ ë§ˆì„¸ìš”
    res = collection.query(
        query_embeddings=[qvec.tolist()],
        n_results=top_k,
        include=["documents", "metadatas", "distances", "embeddings"],  # â† ì—¬ê¸°ì„œ ìˆ˜ì •
    )

    # idsëŠ” includeì— ì—†ì–´ë„ ê¸°ë³¸ìœ¼ë¡œ ë‚´ë ¤ì˜µë‹ˆë‹¤.
    ids      = (res.get("ids") or [[]])[0]
    dists    = (res.get("distances") or [[]])[0]
    docs_txt = (res.get("documents") or [[]])[0]
    metas    = (res.get("metadatas") or [[]])[0]
    embeds   = (res.get("embeddings") or [[]])[0]

    docs = []
    for id_, dist, txt, meta, emb in zip(ids, dists, docs_txt, metas, embeds):
        docs.append({
            "id": id_,
            "distance": float(dist),
            "document": txt,
            "metadata": meta,
            # ì´í›„ MMR ë“±ì—ì„œ ì“°ë ¤ë©´ ë²¡í„°ë„ ë³´ê´€
            "embedding": np.asarray(emb, dtype="float32")
        })

    # ê±°ë¦¬(ì‘ì„ìˆ˜ë¡ ìœ ì‚¬) ê¸°ì¤€ ì •ë ¬
    docs.sort(key=lambda d: d["distance"])
    return docs



# ===== 3) RAG í”„ë¡¬í”„íŠ¸ ë¹Œë” =====
def build_rag_prompt(product_name: str, product_description: str, retrieved: List[Dict[str, Any]], top_n: int, graph_context: str = "") -> Tuple[str, str]:
    """
    - system: ì»¨í…ìŠ¤íŠ¸ ë‚´ì—ì„œë§Œ ë‹µí•˜ë„ë¡ ê°€ë“œ
    - user: ì§ˆë¬¸ + ì»¨í…ìŠ¤íŠ¸ + JSON ìŠ¤í‚¤ë§ˆ(ì—„ê²©)
    """
    system = (
        "ë‹¹ì‹ ì€ êµ­ì œë¬´ì—­ HS ì½”ë“œ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n\n"
        "ê·œì¹™:\n"
        "1) ì œê³µëœ context ë‚´ì˜ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì—¬ íŒë‹¨í•©ë‹ˆë‹¤.\n"
        "2) HS Code ê³„ì¸µ êµ¬ì¡°(GraphDB Context)ëŠ” ì „ì²´ HS Code dataì´ë©°\n"
        "   í’ˆëª©ë¶„ë¥˜ì‚¬ë¡€(VectorDB Context)ëŠ” classify Case dataì…ë‹ˆë‹¤.\n"
        "3) ê³„ì¸µ êµ¬ì¡°ì™€ ë‹¤ë¥¸ ì½”ë“œëŠ” ì ˆëŒ€ ì œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
        "4) ì¶”ì²œí•˜ëŠ” HS CodeëŠ” ë°˜ë“œì‹œ 10ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤.\n"
        "5) í•­ìƒ ì‘ë‹µì€ strict JSON formatìœ¼ë¡œë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
        "6) í™•ì‹ ì´ ì—†ì„ ê²½ìš° 'candidates': [] ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤."
    )

    # ===== ì—¬ê¸°ë¶€í„° ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡ êµ¬ì„± ë¶€ë¶„ë§Œ ìš”ì²­í•œ ë°©ì‹ìœ¼ë¡œ êµì²´ =====
    def _pick(meta, keys, default=""):
        for k in keys:
            v = meta.get(k)
            if v not in (None, ""):
                return str(v)
        return default

    def _fallback_name_from_body(body: str) -> str:
        # ë³¸ë¬¸ ì²« ì¤„ì— "ìƒí’ˆëª…: ..." íŒ¨í„´ì´ ìì£¼ ìˆìœ¼ë¯€ë¡œ ê±°ê¸°ì„œ ë³´ì • ì¶”ì¶œ
        m = re.search(r"^ìƒí’ˆëª…:\s*(.+)$", body, flags=re.MULTILINE)
        return m.group(1).strip() if m else ""

    # ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡(ìµœëŒ€ 6~10ê°œ ê¶Œì¥)
    blocks = []
    for d in retrieved[:10]:
        meta = d.get("metadata", {}) or {}
        body = (d.get("document") or "").strip()

        # 1) ë©”íƒ€ ê¸°ì¤€(ì‹¤ì¸¡ í‚¤ì— ë§ì¶¤) + 2) ë³¸ë¬¸ ë³´ì • ì¶”ì¶œ
        hs   = _pick(meta, ["HSCode", "hs_code", "HS", "HSë¶€í˜¸"])
        name = _pick(meta, ["ìƒí’ˆëª…", "í•œê¸€í’ˆëª©ëª…", "title", "í’ˆëª©ëª…"]) or _fallback_name_from_body(body)
        date = _pick(meta, ["ì‹œí–‰ì¼ì", "ë°œí–‰ì¼"])

        # ì„ íƒ: body ê¸¸ì´ ì•ˆì „ ì ˆë‹¨
        max_chars = 1200
        if len(body) > max_chars:
            body = body[:max_chars] + "â€¦"

        # distancesëŠ” query() ì‚¬ìš© ì‹œì—ë§Œ ì¡´ì¬. get()ì´ë©´ ì—†ìŒ â†’ 0.0
        dist = d.get("distance", 0.0)
        try:
            dist = float(dist)
        except Exception:
            dist = 0.0

        blocks.append(
            f"[DOC id={d.get('id')} dist={dist:.4f}]\n"
            f"ìƒí’ˆëª…: {name}\nHSCode: {hs}\nì‹œí–‰ì¼ì: {date}\në³¸ë¬¸:\n{body}\n"
        )

    vector_context = "\n\n".join(blocks) if blocks else "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"
    # ===== êµì²´ ë =====

    # GraphDB context ì¶”ê°€
    graph_section = ""
    if graph_context.strip():
        graph_section = f"{graph_context}"
    else:
        graph_section = "(GraphDB ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"

    user = f"""
ë‹¤ìŒ ì œí’ˆì˜ HS ì½”ë“œ ìƒìœ„ {top_n} í›„ë³´ë¥¼ ì¶”ì²œí•˜ì„¸ìš”. 
**ì¤‘ìš”: ì¶”ì²œí•˜ëŠ” ëª¨ë“  HS CodeëŠ” ë°˜ë“œì‹œ 10ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: 9405.40.10.00).**

[ì…ë ¥]
- Product Name: {product_name}
- Product Description: {product_description}

================================================
[context]
[HS Code ê³„ì¸µ êµ¬ì¡° Context â€” GraphDB Retrieved]
(ëª¨ë“  ë°ì´í„°ëŠ” HS ê³µì‹ nomenclature ê¸°ë°˜)
{graph_section}
================================================

[í’ˆëª©ë¶„ë¥˜ì‚¬ë¡€ Context â€” VectorDB Retrieved]
(ì •ë¶€ í’ˆëª©ë¶„ë¥˜ì‚¬ë¡€ ë¬¸ì„œ ê¸°ë°˜ ê·¼ê±° ìë£Œ)
{vector_context}  
================================================

[ì‘ë‹µ í˜•ì‹: strict JSON â€” ì¶”ê°€ í‚¤ ê¸ˆì§€]
{{
  "candidates": [
    {{
      "hs_code": "string",          // ë°˜ë“œì‹œ 10ìë¦¬ HS Code (ì˜ˆ: 9405.40.10.00)
      "title": "string",
      "reason": "string",           // í•œêµ­ì–´, 200ì ì´ë‚´
      "citations": [
        {{"type": "graph", "code": "string"}},   // GraphDB ê·¼ê±°
        {{"type": "case", "doc_id": "string"}}   // VectorDB ê·¼ê±°
      ]
    }}
  ]
}}

í•„ìˆ˜ ê·œì¹™:
1) í›„ë³´ëŠ” ìµœëŒ€ {top_n}ê°œ.
2) hs_codeëŠ” ë°˜ë“œì‹œ 10ìë¦¬ì—¬ì•¼ í•©ë‹ˆë‹¤ (ì˜ˆ: 9405.40.10.00).
3) citationsëŠ” ìµœì†Œ 1ê°œ ì´ìƒ í¬í•¨.
4) citations.typeì€ ë°˜ë“œì‹œ "graph" ë˜ëŠ” "case"ë§Œ ê°€ëŠ¥.
"""
    return system, user


# ===== 4) ìµœì¢… í•¨ìˆ˜: RAG + JSON ëª¨ë“œ =====
def classify_hs_code_rag(product_name: str, product_description: str, top_n: int = 3) -> Dict[str, Any]:
    """
    1) Chromaì—ì„œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    2) GraphRAGì—ì„œ ê³„ì¸µ êµ¬ì¡° ì •ë³´ ê²€ìƒ‰
    3) ì»¨í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ LLM(JSON ê°•ì œ) í˜¸ì¶œ
    4) JSON íŒŒì‹±í•´ ë°˜í™˜
    """
    # 1) Chroma ê²€ìƒ‰
    emb = QueryEmbedder(EMBED_MODEL)
    col = open_chroma_collection(CHROMA_DIR, COLLECTION_NAME)
    original_query_text = f"{product_name}\n{product_description}"
    keyword_query_text = extract_keywords_advanced(original_query_text)
    
    hits = search_chroma(col, emb, keyword_query_text, top_k=max(8, top_n*3))

    # 2) GraphRAGì—ì„œ ê³„ì¸µ êµ¬ì¡° ì •ë³´ ê²€ìƒ‰
    try:
        graph_rag = GraphRAG()
        graph_context = graph_rag.get_final_context(original_query_text, k=5)
    except Exception as e:
        print(f"GraphRAG ì˜¤ë¥˜: {e}")
        graph_context = ""

    # 3) í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    sys_prompt, user_prompt = build_rag_prompt(product_name, product_description, hits, top_n, graph_context)

    # 4) JSON ëª¨ë“œ í˜¸ì¶œ
    response = client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL", "gpt-4o-mini"),
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user",   "content": user_prompt}
        ],
        temperature=0.2,
        response_format={"type": "json_object"}  # <- í•µì‹¬: ìˆœìˆ˜ JSONë§Œ ë°˜í™˜
    )

    output_text = response.choices[0].message.content.strip()

    # 5) ì•ˆì „ íŒŒì‹±
    result, err = _parse_json_safely(output_text)
    if err:
        result = {"error": err, "raw_output": output_text}

    return result


# ===== 5) GraphRAG í†µí•© í—¬í¼ í•¨ìˆ˜ =====
def get_enhanced_context(product_name: str, product_description: str, k: int = 5) -> Dict[str, str]:
    """
    ChromaDBì™€ GraphDBì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ê°€ì ¸ì˜¤ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        product_name: ìƒí’ˆëª…
        product_description: ìƒí’ˆì„¤ëª…
        k: GraphDBì—ì„œ ê²€ìƒ‰í•  í›„ë³´ ê°œìˆ˜
        
    Returns:
        Dict[str, str]: chroma_contextì™€ graph_contextë¥¼ í¬í•¨í•œ ë”•ì…”ë„ˆë¦¬
    """
    # ChromaDB ì»¨í…ìŠ¤íŠ¸
    emb = QueryEmbedder(EMBED_MODEL)
    col = open_chroma_collection(CHROMA_DIR, COLLECTION_NAME)
    original_query_text = f"{product_name}\n{product_description}"
    keyword_query_text = extract_keywords_advanced(original_query_text)
    
    hits = search_chroma(col, emb, keyword_query_text, top_k=8)
    
    # ChromaDB ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    def _pick(meta, keys, default=""):
        for k in keys:
            v = meta.get(k)
            if v not in (None, ""):
                return str(v)
        return default

    def _fallback_name_from_body(body: str) -> str:
        m = re.search(r"^ìƒí’ˆëª…:\s*(.+)$", body, flags=re.MULTILINE)
        return m.group(1).strip() if m else ""

    blocks = []
    for d in hits[:10]:
        meta = d.get("metadata", {}) or {}
        body = (d.get("document") or "").strip()

        hs   = _pick(meta, ["HSCode", "hs_code", "HS", "HSë¶€í˜¸"])
        name = _pick(meta, ["ìƒí’ˆëª…", "í•œê¸€í’ˆëª©ëª…", "title", "í’ˆëª©ëª…"]) or _fallback_name_from_body(body)
        date = _pick(meta, ["ì‹œí–‰ì¼ì", "ë°œí–‰ì¼"])

        max_chars = 1200
        if len(body) > max_chars:
            body = body[:max_chars] + "â€¦"

        dist = d.get("distance", 0.0)
        try:
            dist = float(dist)
        except Exception:
            dist = 0.0

        blocks.append(
            f"[DOC id={d.get('id')} dist={dist:.4f}]\n"
            f"ìƒí’ˆëª…: {name}\nHSCode: {hs}\nì‹œí–‰ì¼ì: {date}\në³¸ë¬¸:\n{body}\n"
        )

    chroma_context = "\n\n".join(blocks) if blocks else "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"
    
    # GraphDB ì»¨í…ìŠ¤íŠ¸
    try:
        graph_rag = GraphRAG()
        graph_context = graph_rag.get_final_context(original_query_text, k=k)
    except Exception as e:
        print(f"GraphRAG ì˜¤ë¥˜: {e}")
        graph_context = ""
    
    return {
        "vector_context": chroma_context,
        "graph_context": graph_context,
        "query_text": original_query_text
    }

# ===== (ìƒˆë¡œ ì¶”ê°€!) RAG ê²°ê³¼ í¬ë§·íŒ… í•¨ìˆ˜ =====
def format_rag_result(result: dict) -> str:
    """RAGê°€ ë°˜í™˜í•œ JSON(dict)ì„ ì±—ë´‡ ë‹µë³€ìš© ë¬¸ìì—´(str)ë¡œ ë³€í™˜"""
    
    candidates = result.get("candidates", [])
    
    if not candidates:
        return "ì¶”ì²œí•  HS Codeë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì…ë ¥ê°’ì„ í™•ì¸í•´ì£¼ì„¸ìš”."

    # ì±—ë´‡ ë‹µë³€ì„ Markdownìœ¼ë¡œ êµ¬ì„±
    response_parts = ["ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì¶”ì²œ ê²°ê³¼ì…ë‹ˆë‹¤:\n"]
    
    for i, candidate in enumerate(candidates):
        response_parts.append(f"### ğŸ… ì¶”ì²œ {i+1}ìˆœìœ„: {candidate.get('hs_code', 'N/A')}")
        
        # ì‹ ë¢°ë„ê°€ ìˆë‹¤ë©´ í‘œì‹œ (ê¸°ì¡´ st.metric ì½”ë“œì™€ ë™ì¼í•˜ê²Œ)
        if 'confidence' in candidate:
            response_parts.append(f"**ì‹ ë¢°ë„:** {candidate.get('confidence', 0.0) * 100:.1f}%")
            
        response_parts.append(f"**í’ˆëª©ëª…:** {candidate.get('title', 'N/A')}\n")
        
        # ê·¼ê±° (Reason)
        response_parts.append(f"**ë¶„ë¥˜ ê·¼ê±°:**\n{candidate.get('reason', 'ê·¼ê±° ì—†ìŒ')}\n")
        
        # ì¸ìš© (Citations)
        citations = candidate.get("citations", [])
        if citations:
            response_parts.append("**ì°¸ê³ í•œ ê·¼ê±°:**")
            cite_list = []
            for cit in citations:
                if cit.get("type") == "graph":
                    cite_list.append(f"- (ê³„ì¸µ) {cit.get('code')}")
                elif cit.get("type") == "case":
                    cite_list.append(f"- (ì‚¬ë¡€) Doc ID: {cit.get('doc_id')}")
            response_parts.append("\n".join(cite_list))
            
        response_parts.append("---") # (êµ¬ë¶„ì„ )

    return "\n".join(response_parts)
# =============================================== ì•„ë˜ë¶€í„° UI

# ===== í…Œë‘ë¦¬ ì œê±°ìš© CSS =====
st.markdown("""
<style>
    /* 1. ì±„íŒ… ëª©ë¡ í…Œë‘ë¦¬ 'ì„ 'ì„ ê°•ì œë¡œ ì œê±° */
    [data-testid="stSidebar"] [data-testid="stVerticalScrollableContainer"] {
        border: none !important;
    }

    /* 2. 'ì „ì²´' ì‚¬ì´ë“œë°”ì˜ ìŠ¤í¬ë¡¤ë°”ë¥¼ ê°•ì œë¡œ ìˆ¨ê¹€ */
    [data-testid="stSidebar"] > div:first-child {
        overflow-y: hidden !important;
    }

    /* 3. ë©”ì¸ ëŒ€í™”ì°½(ì±„íŒ… ë²„ë¸”) í…ìŠ¤íŠ¸ í¬ê¸° í‚¤ìš°ê¸° */
    [data-testid="stChatMessage"] {
        font-size: 1.1rem; 
    }
</style>
""", unsafe_allow_html=True)
# ========================================

st.title("HS Code ì¶”ì²œ ì‹œìŠ¤í…œ ğŸ¤–")

# --- ì±—ë´‡ íˆìŠ¤í† ë¦¬ ë¡œì§ (Session State) ---

# 1. "ê¸°ì–µ ì €ì¥ì†Œ" (Session State) ì´ˆê¸°í™”
if "chat_archive" not in st.session_state:
    st.session_state.chat_archive = {}     # (ëŒ€í™” ë³´ê´€ì†Œ)
    st.session_state.current_chat_id = None  # (í˜„ì¬ í™œì„±í™”ëœ ID)
    
# 2. "í˜„ì¬ ì±„íŒ…ë°©"ì´ ì—†ìœ¼ë©´ -> 'ìƒˆ ì±„íŒ…ë°©'ì„ 1ê°œ ë§Œë“¦
# (ë˜ëŠ” ë°©ê¸ˆ ì±„íŒ…ë°©ì„ ì‚­ì œí•´ì„œ current_chat_idê°€ Noneì´ ëœ ê²½ìš°)
if st.session_state.current_chat_id is None:
    # ë‚¨ì€ ì±„íŒ…ë°©ì´ ìˆë‹¤ë©´, ê·¸ ì¤‘ ê°€ì¥ ìµœì‹  ì±„íŒ…ì„ í™œì„±í™”
    if st.session_state.chat_archive:
        st.session_state.current_chat_id = list(st.session_state.chat_archive.keys())[-1]
    # ë‚¨ì€ ì±„íŒ…ë°©ì´ í•˜ë‚˜ë„ ì—†ë‹¤ë©´, ìƒˆ ì±„íŒ…ë°© ìƒì„±
    else:
        chat_id = str(uuid.uuid4())
        st.session_state.current_chat_id = chat_id
        st.session_state.chat_archive[chat_id] = {
            "id": chat_id,
            "title": "New Chat (ìƒˆ ëŒ€í™”)",
            "messages": [
                {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! HS Code ì¶”ì²œì„ ì‹œì‘í•©ë‹ˆë‹¤. ë¶„ë¥˜í•  'ìƒí’ˆëª…'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}
            ],
            "step": "awaiting_name",
            "product_name": "",
            "product_desc": "",
            "is_new": True  # (ìë™ ì´ë¦„ ë³€ê²½ì„ ìœ„í•œ í”Œë˜ê·¸)
        }

# --- 3. ì‚¬ì´ë“œë°” (Sidebar) ë¡œì§ (Plan C: í•˜ë‹¨ ê´€ë¦¬) ---

with st.sidebar:
    st.header("ëŒ€í™” ëª©ë¡")
    
    # (A) "ìƒˆ ëŒ€í™”" ë²„íŠ¼ (ì´ì „ê³¼ ë™ì¼)
    if st.button("ğŸ“ ìƒˆë¡œìš´ ëŒ€í™” (New Chat)", use_container_width=True):
        new_chat_id = str(uuid.uuid4())
        st.session_state.current_chat_id = new_chat_id
        st.session_state.chat_archive[new_chat_id] = {
            "id": new_chat_id,
            "title": "New Chat (ìƒˆ ëŒ€í™”)",
            "messages": [
                {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! HS Code ì¶”ì²œì„ ì‹œì‘í•©ë‹ˆë‹¤. ë¶„ë¥˜í•  'ìƒí’ˆëª…'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}
            ],
            "step": "awaiting_name",
            "product_name": "",
            "product_desc": "",
            "is_new": True
        }
        st.rerun()

    st.divider()

    # ---  ìŠ¤í¬ë¡¤ë˜ëŠ” ì±„íŒ… ëª©ë¡ ---
    st.caption("ì±„íŒ…ë°© ì„ íƒ")
    scroll_container = st.container(height=400) 
    
    with scroll_container:
        chat_ids = list(st.session_state.chat_archive.keys())
        
        for chat_id in reversed(chat_ids):
            if chat_id not in st.session_state.chat_archive:
                continue
                
            chat = st.session_state.chat_archive[chat_id]
            is_active = (chat_id == st.session_state.current_chat_id)
            
            # (í™œì„±í™”ëœ ë²„íŠ¼ì€ íšŒìƒ‰ìœ¼ë¡œ ë¹„í™œì„±í™”)
            if st.button(
                chat["title"], 
                key=chat_id, 
                use_container_width=True, 
                #help=f"'{chat['title']}' ëŒ€í™” ì—´ê¸°",
                disabled=is_active 
            ):
                st.session_state.current_chat_id = chat_id
                st.rerun()
            
    # --- ê³ ì •ë˜ëŠ” ì„¤ì • ë¸”ë¡ ---
    # (dividerì™€ headerê°€ ìŠ¤í¬ë¡¤ ì»¨í…Œì´ë„ˆ "ë°–"ì— ìˆìŒ)
    st.divider()
    st.header("ì±„íŒ…ë°© ì„¤ì •")
    st.caption("í˜„ì¬ í™œì„±í™”ëœ ì±„íŒ…ë°©ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.")
    
    # (í˜„ì¬ í™œì„±í™”ëœ ì±„íŒ…ë°© ì •ë³´ë¥¼ ê°€ì ¸ì˜´)
    active_chat_id = st.session_state.current_chat_id
    active_chat = st.session_state.chat_archive[active_chat_id]

    #  ì´ë¦„ ìˆ˜ì • ê¸°ëŠ¥ 
    # (keyë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½í•˜ì—¬, ì±„íŒ…ë°©ì„ ë°”ê¿€ ë•Œë§ˆë‹¤ ê°’ì´ ìƒˆë¡œ ë¡œë“œë˜ê²Œ í•¨)
    new_title = st.text_input(
        "ì´ë¦„ ìˆ˜ì •:", 
        value=active_chat["title"], 
        key=f"rename_input_{active_chat_id}" 
    )
    
    # (keyë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½)
    if st.button("ì´ë¦„ ì €ì¥", key=f"save_rename_{active_chat_id}", use_container_width=True): 
        active_chat["title"] = new_title
        active_chat["is_new"] = False # ìˆ˜ë™ìœ¼ë¡œ ì´ë¦„ ë°”ê¿ˆ
        st.rerun()

    # ì‚­ì œ ê¸°ëŠ¥ (keyë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½)
    if st.button("âš ï¸ ì´ ì±„íŒ… ì‚­ì œ", key=f"delete_chat_{active_chat_id}", use_container_width=True): 
        # (1) ë³´ê´€ì†Œì—ì„œ í˜„ì¬ ì±„íŒ… ID ì‚­ì œ
        del st.session_state.chat_archive[active_chat_id]
        # (2) í˜„ì¬ IDë¥¼ Noneìœ¼ë¡œ ì„¤ì • (-> 2ë²ˆ ë¡œì§ì´ ë‹¤ìŒ ì±„íŒ…ë°©ì„ ì°¾ê±°ë‚˜ ìƒˆë¡œ ë§Œë“¦)
        st.session_state.current_chat_id = None
        st.rerun() # ìƒˆë¡œê³ ì¹¨
            

# ---  ë©”ì¸ ì±„íŒ…ì°½ (Main Chat) ë¡œì§ ---

#  í˜„ì¬ í™œì„±í™”ëœ ì±„íŒ…ë°© IDì™€ ì •ë³´ë¥¼ ê°€ì ¸ì˜´
active_chat_id = st.session_state.current_chat_id
active_chat = st.session_state.chat_archive[active_chat_id]

# ëŒ€í™” ë‚´ì—­ ê·¸ë¦¬ê¸°
for message in active_chat["messages"]:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ì±—ë´‡ ì…ë ¥ì°½
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    
    active_chat["messages"].append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)

    current_step = active_chat["step"]
    
    # --- ìƒíƒœ 1: "ìƒí’ˆëª…"ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ (ìë™ ì´ë¦„ ë³€ê²½ ìˆ˜ì •!) ---
    if current_step == "awaiting_name":
        active_chat["product_name"] = prompt
        
        # "is_new" í”Œë˜ê·¸ê°€ Trueì¼ ë•Œë§Œ ìë™ ì´ë¦„ ë³€ê²½
        if active_chat["is_new"]:
            active_chat["title"] = f"í’ˆëª©: {prompt[:50]}..."
            active_chat["is_new"] = False # ìë™ ì´ë¦„ ë³€ê²½ ì™„ë£Œ
            
        active_chat["step"] = "awaiting_desc"
        response_text = f"ìƒí’ˆëª… '{prompt}'ì„(ë¥¼) ë°›ì•˜ìŠµë‹ˆë‹¤. ì´ì œ 'ìƒí’ˆ ì„¤ëª…'ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."

    # --- ìƒíƒœ 2: "ìƒí’ˆ ì„¤ëª…"ì„ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘ ---
    elif current_step == "awaiting_desc":
        # (ì´ì „ ì½”ë“œì™€ 100% ë™ì¼)
        active_chat["product_desc"] = prompt
        active_chat["step"] = "processing"
        
        with st.chat_message("assistant"):
            with st.spinner("ìƒí’ˆëª…ê³¼ ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œì„ ì‹œì‘í•©ë‹ˆë‹¤... (10~20ì´ˆ ì†Œìš”)"):
                try:
                    result_json = classify_hs_code_rag(
                        product_name=active_chat["product_name"],
                        product_description=active_chat["product_desc"],
                        top_n=3
                    )
                    response_text = format_rag_result(result_json)
                except Exception as e:
                    response_text = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
                    st.error(f"RAG í•¨ìˆ˜ ì˜¤ë¥˜: {e}")
        
        active_chat["step"] = "awaiting_name"
        active_chat["product_name"] = ""
        active_chat["product_desc"] = ""
        response_text += "\n\n---\në¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì¶”ì²œì„ ì›í•˜ì‹œë©´ 'ìƒí’ˆëª…'ì„ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”."

    # --- ìƒíƒœ 3: ì²˜ë¦¬ ì¤‘ (Processing) ---
    elif current_step == "processing":
        response_text = "í˜„ì¬ ì´ì „ ìš”ì²­ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”..."
        
    # (D) ìœ„ì—ì„œ ì¤€ë¹„ëœ ë´‡ì˜ ë‹µë³€(response_text)ì„ í™”ë©´ì— ê·¸ë¦¬ê³  "ê¸°ì–µ"
    if active_chat["step"] != "processing":
        with st.chat_message("assistant"):
            st.markdown(response_text)
        active_chat["messages"].append({"role": "assistant", "content": response_text})
    
    st.rerun() # ë©”ì¸ ì±„íŒ…/ì‚¬ì´ë“œë°” ë™ê¸°í™”ë¥¼ ìœ„í•´ ìƒˆë¡œê³ ì¹¨

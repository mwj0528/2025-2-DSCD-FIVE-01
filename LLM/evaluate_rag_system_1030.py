# evaluate_rag_system.py
"""
RAG ê¸°ë°˜ HS Code ì¶”ì²œ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€ (ê°„ê²°/ì•ˆì • ë²„ì „)
- Top-1, Top-3, Top-5 ì •í™•ë„ë§Œ ê³„ì‚°/ì¶œë ¥
- í–‰ë³„ íƒ€ì„ì•„ì›ƒ/í•˜íŠ¸ë¹„íŠ¸ ë¡œê·¸/ìƒ˜í”Œ ì œí•œ ì§€ì›
- í•„ìš” ì‹œ ìš”ì•½ JSONë§Œ ì €ì¥

ì‹¤í–‰:
    # ì²« ì‹¤í–‰(ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ ê¶Œì¥)
    TOKENIZERS_PARALLELISM=false OMP_NUM_THREADS=1 \
    EVAL_MAX_SAMPLES=5 EVAL_TIMEOUT_SEC=45 \
    python evaluate_rag_system.py

í•„ìˆ˜:
    1) RAG.py ë˜ëŠ” rag_hs_prompt.py ë‚´ classify_hs_code_rag í•¨ìˆ˜ê°€ import ê°€ëŠ¥
    2) HScode_100ê°œ_filled.xlsx ì¡´ì¬(í˜¹ì€ ìƒìœ„ í´ë”)
    3) .env ì— OPENAI_API_KEY ì„¤ì •
"""

import os
# êµì°©/ê³¼ì ìœ  ë°©ì§€ ê¶Œì¥ ì„¤ì •(ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
os.environ.setdefault("TOKENIZERS_PARALLELISM", "false")
os.environ.setdefault("OMP_NUM_THREADS", "1")

import re
import sys
import json
import time
import signal
import numpy as np
import pandas as pd
from typing import Dict, List, Optional
from datetime import datetime

# =========================
# RAG ëª¨ë“ˆ import (RAG.py â†’ rag_hs_prompt.py ìˆœì„œë¡œ ì‹œë„)
# ì´ í•¨ìˆ˜ê°€ VectorDB + GraphDB + LLMì˜ ì „ì²´ ê³¼ì •ì„ ì‹¤í–‰
# =========================
try:
    from RAG import classify_hs_code_rag  # ì‚¬ìš©ì í™˜ê²½ ìš°ì„ 
except ImportError:
    try:
        from rag_hs_prompt import classify_hs_code_rag  # ëŒ€ì²´ ê²½ë¡œ
    except ImportError:
        print("âŒ classify_hs_code_rag ì„í¬íŠ¸ ì‹¤íŒ¨. RAG.py ë˜ëŠ” rag_hs_prompt.py ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)


class HSCodeEvaluator:
    def __init__(self, excel_path: str = None):
        # ë””ë²„ê·¸/ì„±ëŠ¥ ì œì–´ í™˜ê²½ë³€ìˆ˜
        self.max_samples = int(os.getenv("EVAL_MAX_SAMPLES", "0"))     # 0ì´ë©´ ì „ì²´
        self.per_item_timeout = int(os.getenv("EVAL_TIMEOUT_SEC", "45"))  # í–‰ë³„ íƒ€ì„ì•„ì›ƒ(ì´ˆ)
        self.top_n = int(os.getenv("EVAL_TOP_N", "5"))                 # ì˜ˆì¸¡ ìƒí•œ(ì •í™•ë„ëŠ” 1/3/5ë§Œ ê³„ì‚°)

        # ì—‘ì…€ ê²½ë¡œ ìë™ íƒìƒ‰
        if excel_path is None:
            for p in [
                "HScode_100ê°œ_with_user_input.xlsx",
                "../HScode_100ê°œ_with_user_input.xlsx",
                "../../HScode_100ê°œ_with_user_input.xlsx",
            ]:
                if os.path.exists(p):
                    excel_path = p
                    break
        if excel_path is None or not os.path.exists(excel_path):
            raise FileNotFoundError("HScode_100ê°œ_with_user_input.xlsx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        self.excel_path = excel_path

    @staticmethod
    def normalize_hs(code: Optional[str], keep_digits: int = 10) -> Optional[str]:
        if code is None or (isinstance(code, float) and np.isnan(code)):
            return None 
        digits = re.sub(r"[^0-9]", "", str(code)) # ì  ì œê±°, 10ìë¦¬ ë§ì¶¤
        if not digits:
            return None
        return (digits[:keep_digits]).ljust(keep_digits, "0")

    def load_test_data(self) -> pd.DataFrame:
        df = pd.read_excel(self.excel_path)

        required_cols = {
            'id': ['ë²ˆí˜¸', 'id', 'ID'],
            'product_name': ['ì‚¬ìš©ì_ìƒí’ˆëª…', 'ìƒí’ˆëª…'],
            'product_desc': ['ì‚¬ìš©ì_ìƒí’ˆì„¤ëª…', 'ìƒí’ˆì„¤ëª…'],
            'gold_hs': ['HSë¶€í˜¸', 'HSCode', 'HSì½”ë“œ']
        }
        # ì‹¤ì œ ì—‘ì…€ì— ìˆëŠ” ì»¬ëŸ¼ëª… ì°¾ê¸°
        col_map = {}
        for target, cands in required_cols.items():
            for c in cands:
                if c in df.columns:
                    col_map[c] = target
                    break
            else:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {cands}")

        test_df = df[list(col_map.keys())].rename(columns=col_map)
        test_df['gold_hs'] = test_df['gold_hs'].apply(lambda x: self.normalize_hs(x, 10))
        test_df = test_df.dropna(subset=['product_name', 'product_desc', 'gold_hs'])

        if self.max_samples > 0:
            test_df = test_df.head(self.max_samples)
            print(f"ğŸ” ë””ë²„ê·¸ ëª¨ë“œ: ìƒìœ„ {len(test_df)}ê°œë§Œ í‰ê°€(EVAL_MAX_SAMPLES).")

        return test_df

    def generate_predictions(self, test_df: pd.DataFrame, top_n: int = 5) -> pd.DataFrame:
        """ì¡°ìš©íˆ ì˜ˆì¸¡ë§Œ ìˆ˜í–‰ + í–‰ë³„ íƒ€ì„ì•„ì›ƒ + í•˜íŠ¸ë¹„íŠ¸ ë¡œê·¸"""
        preds: List[Dict] = []

        class _Timeout(Exception):
            ...

        def _handler(signum, frame):
            raise _Timeout()

        signal.signal(signal.SIGALRM, _handler)

        total = len(test_df)
        for i, (_, row) in enumerate(test_df.iterrows(), start=1):
            product_name = str(row['product_name']).strip()
            product_desc = str(row['product_desc']).strip()
            pred_list: List[str] = []

            try:
                signal.alarm(self.per_item_timeout)  # â±ï¸ í–‰ë³„ íƒ€ì„ì•„ì›ƒ
                t0 = time.time()
                result = classify_hs_code_rag(       # RAG ì‹œìŠ¤í…œ í˜¸ì¶œ (VectorDB + GraphDB + LLM ì „ì²´ ê³¼ì •)
                    product_name=product_name,
                    product_description=product_desc,
                    top_n=top_n
                )
                signal.alarm(0)

                if isinstance(result, dict):
                    for cand in result.get("candidates", []):
                        norm = self.normalize_hs(cand.get("hs_code", ""), 10)
                        if norm:
                            pred_list.append(norm)

                # 5ê°œë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥ (í•˜íŠ¸ë¹„íŠ¸)
                if i % 5 == 0 or i == total:
                    dt = time.time() - t0
                    print(f"   Â· ì§„í–‰ {i}/{total} (last {dt:.1f}s, preds={len(pred_list)})")

            except _Timeout:
                signal.alarm(0)
                print(f"   Â· ì§„í–‰ {i}/{total} (timeout {self.per_item_timeout}s, ê±´ë„ˆëœ€)")
                pred_list = []
            except Exception as e:
                signal.alarm(0)
                # ì¡°ìš©í•˜ì§€ë§Œ ì›ì¸ íŒíŠ¸ëŠ” í•œ ì¤„
                print(f"   Â· ì§„í–‰ {i}/{total} (error: {str(e)[:80]})")
                pred_list = []

            preds.append({'id': row['id'], 'pred_list': pred_list})

        return pd.DataFrame(preds)

    @staticmethod
    def compute_metrics(test_df: pd.DataFrame, pred_df: pd.DataFrame) -> Dict:
        """Top-1/3/5 ì •í™•ë„ë§Œ ê³„ì‚°"""
        df = test_df.merge(pred_df, on='id', how='left')
        df['pred_list'] = df['pred_list'].apply(lambda x: x if isinstance(x, list) else [])

        def calc_hits(row):
            gold = row['gold_hs']
            preds = row['pred_list']
            return pd.Series({
                'hit_top1': 1 if (len(preds) >= 1 and gold == preds[0]) else 0,
                'hit_top3': 1 if gold in preds[:3] else 0,
                'hit_top5': 1 if gold in preds[:5] else 0,
            })

        hits = df.apply(calc_hits, axis=1)
        detailed = pd.concat([df, hits], axis=1)

        total = len(detailed)
        top1_correct = int(detailed['hit_top1'].sum())
        top3_correct = int(detailed['hit_top3'].sum())
        top5_correct = int(detailed['hit_top5'].sum())

        report = {
            'total_samples': int(total),
            'valid_predictions': int(detailed['pred_list'].apply(len).gt(0).sum()),
            'top1_accuracy': float(top1_correct / total) if total else 0.0,
            'top3_accuracy': float(top3_correct / total) if total else 0.0,
            'top5_accuracy': float(top5_correct / total) if total else 0.0,
            'top1_correct': top1_correct,
            'top3_correct': top3_correct,
            'top5_correct': top5_correct
        }
        return report

    @staticmethod
    def save_report(report: Dict, output_dir: str = "."):
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        os.makedirs(output_dir, exist_ok=True)
        path = os.path.join(output_dir, f"evaluation_report_{ts}.json")
        with open(path, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        return path

    def run(self, save_output: bool = True, output_dir: str = "."):
        # 1) ë°ì´í„° ë¡œë“œ
        test_df = self.load_test_data()

        # 2) ì˜ˆì¸¡ (Top-N ìƒì„± â†’ Top-5 ì •í™•ë„ê¹Œì§€ ê³„ì‚° ê°€ëŠ¥)
        pred_df = self.generate_predictions(test_df, top_n=max(5, self.top_n))

        # 3) ì§€í‘œ ê³„ì‚°(Top-1/3/5ë§Œ)
        report = self.compute_metrics(test_df, pred_df)

        # 4) ìµœì†Œ ì¶œë ¥(ì •í™•ë„ë§Œ)
        print("ğŸš€ HS Code RAG ì„±ëŠ¥ í‰ê°€ (Top-1/3/5)")
        print(f"ì „ì²´ ìƒ˜í”Œ ìˆ˜: {report['total_samples']} | ìœ íš¨ ì˜ˆì¸¡ ìˆ˜: {report['valid_predictions']}")
        print(f"Top-1 ì •í™•ë„: {report['top1_accuracy']:.2%} ({report['top1_correct']}/{report['total_samples']})")
        print(f"Top-3 ì •í™•ë„: {report['top3_accuracy']:.2%} ({report['top3_correct']}/{report['total_samples']})")
        print(f"Top-5 ì •í™•ë„: {report['top5_accuracy']:.2%} ({report['top5_correct']}/{report['total_samples']})")

        saved = None
        if save_output:
            saved = self.save_report(report, output_dir=output_dir)
            print(f"(ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥: {saved})")
        return report, saved


if __name__ == "__main__":
    try:
        evaluator = HSCodeEvaluator()
        evaluator.run(save_output=True, output_dir=".")
    except Exception as e:
        # í•œ ì¤„ë§Œ ê°„ë‹¨íˆ í‘œê¸° (ìì„¸í•œ ìŠ¤íƒ ì¶œë ¥ ì—†ìŒ)
        print(f"ì‹¤í–‰ ì˜¤ë¥˜: {str(e)}")
